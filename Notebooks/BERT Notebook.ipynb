{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "47156fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156055</th>\n",
       "      <td>156056</td>\n",
       "      <td>8544</td>\n",
       "      <td>Hearst 's</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156056</th>\n",
       "      <td>156057</td>\n",
       "      <td>8544</td>\n",
       "      <td>forced avuncular chortles</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156057</th>\n",
       "      <td>156058</td>\n",
       "      <td>8544</td>\n",
       "      <td>avuncular chortles</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156058</th>\n",
       "      <td>156059</td>\n",
       "      <td>8544</td>\n",
       "      <td>avuncular</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156059</th>\n",
       "      <td>156060</td>\n",
       "      <td>8544</td>\n",
       "      <td>chortles</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156060 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        PhraseId  SentenceId  \\\n",
       "0              1           1   \n",
       "1              2           1   \n",
       "2              3           1   \n",
       "3              4           1   \n",
       "4              5           1   \n",
       "...          ...         ...   \n",
       "156055    156056        8544   \n",
       "156056    156057        8544   \n",
       "156057    156058        8544   \n",
       "156058    156059        8544   \n",
       "156059    156060        8544   \n",
       "\n",
       "                                                   Phrase  Sentiment  \n",
       "0       A series of escapades demonstrating the adage ...          1  \n",
       "1       A series of escapades demonstrating the adage ...          2  \n",
       "2                                                A series          2  \n",
       "3                                                       A          2  \n",
       "4                                                  series          2  \n",
       "...                                                   ...        ...  \n",
       "156055                                          Hearst 's          2  \n",
       "156056                          forced avuncular chortles          1  \n",
       "156057                                 avuncular chortles          3  \n",
       "156058                                          avuncular          2  \n",
       "156059                                           chortles          2  \n",
       "\n",
       "[156060 rows x 4 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read TSV file into DataFrame\n",
    "df = pd.read_table('Project Files/train.tsv/train.tsv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "40d2e17d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>of escapades demonstrating the adage that what...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>of</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>escapades demonstrating the adage that what is...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>escapades</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>demonstrating the adage that what is good for ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "5         6           1  of escapades demonstrating the adage that what...   \n",
       "6         7           1                                                 of   \n",
       "7         8           1  escapades demonstrating the adage that what is...   \n",
       "8         9           1                                          escapades   \n",
       "9        10           1  demonstrating the adage that what is good for ...   \n",
       "\n",
       "   Sentiment  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  \n",
       "5          2  \n",
       "6          2  \n",
       "7          2  \n",
       "8          2  \n",
       "9          2  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1be52d5",
   "metadata": {},
   "source": [
    "We can see that the sentences are divided into phrases which are assigned sentiments in the above data sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fe8a89",
   "metadata": {},
   "source": [
    "## To chech if all  the phrases are assigned a unique ID, making them all of them unique identifier for records in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cffb7988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _total_number_phrases(df, column_name):\n",
    "    phrases = df[column_name]\n",
    "    return phrases, len(phrases)\n",
    "\n",
    "phrases, _n_phrases = _total_number_phrases(df, \"PhraseId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "de9337e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156060"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Checking the length of list of unique phrase set\n",
    "len(list(set(phrases)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "afa4ceb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156060"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Checking the length of list of all phrases\n",
    "len(phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4d259684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All the Phrases have UNIQUE ID.\n"
     ]
    }
   ],
   "source": [
    "def _are_unique(phrases):\n",
    "    if len(list(set(phrases)))==len(phrases):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "if _are_unique(phrases):\n",
    "    print(\"All the Phrases have UNIQUE ID.\")\n",
    "else:\n",
    "    print(\"Phrase ID is not unique.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6177fd95",
   "metadata": {},
   "source": [
    "## Analyzing all the attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c6ec3b91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Sentiments\n",
    "set(df[\"Sentiment\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59183090",
   "metadata": {},
   "source": [
    "There are 5 sentiments classes in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1c0bcf2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8529"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(df['SentenceId']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a223615",
   "metadata": {},
   "source": [
    "There are unique 8529 sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cf658a5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156060"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(set(df['PhraseId']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed991697",
   "metadata": {},
   "source": [
    "There are 156060 unique phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c337159f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156060"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(df['Phrase']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95357cc6",
   "metadata": {},
   "source": [
    "The phrase content is unique as well and is 156060 in number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a9bd9aca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PhraseId      0\n",
       "SentenceId    0\n",
       "Phrase        0\n",
       "Sentiment     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7951dd5",
   "metadata": {},
   "source": [
    "## Finding Embeddings of the Phrases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930d6fa3",
   "metadata": {},
   "source": [
    "SETTING UP CLASS FOR INDEPENDENT MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b674646c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "class PreTrained_EmbeddingModels:\n",
    "    def __init__(self, model_url=None, model_name=None, model=None):\n",
    "        self.model_url = model_url\n",
    "        self.model_name = model_name\n",
    "        self.model = model\n",
    "        self._load(model_url)\n",
    "        \n",
    "    def _load(self, model_url):\n",
    "        if self.model != None:\n",
    "            print(\"Model Switching is disabled.\")\n",
    "            return\n",
    "        self.model = SentenceTransformer(model_url)\n",
    "        \n",
    "    def _get_model(self):\n",
    "        return self.model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dd62d5",
   "metadata": {},
   "source": [
    "LOADING BERT MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "25c617bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_instance_bert = PreTrained_EmbeddingModels(model_url=\"sentence-transformers/bert-base-nli-mean-tokens\", model_name=\"BERT\")._get_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5868983",
   "metadata": {},
   "source": [
    "FINDING EMBEDDINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "55c7445a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_bert = model_instance_bert.encode(df['Phrase'].tolist()[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f981ef54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('mypickle.pickle', 'wb') as f:\n",
    "    pickle.dump([embeddings_bert], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9db27804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 99,\n",
       " 100,\n",
       " 101,\n",
       " 102,\n",
       " 103,\n",
       " 104,\n",
       " 105,\n",
       " 106,\n",
       " 107,\n",
       " 108,\n",
       " 109,\n",
       " 110,\n",
       " 111,\n",
       " 112,\n",
       " 113,\n",
       " 114,\n",
       " 115,\n",
       " 116,\n",
       " 117,\n",
       " 118,\n",
       " 119,\n",
       " 120,\n",
       " 121,\n",
       " 122,\n",
       " 123,\n",
       " 124,\n",
       " 125,\n",
       " 126,\n",
       " 127,\n",
       " 128,\n",
       " 129,\n",
       " 130,\n",
       " 131,\n",
       " 132,\n",
       " 133,\n",
       " 134,\n",
       " 135,\n",
       " 136,\n",
       " 137,\n",
       " 138,\n",
       " 139,\n",
       " 140,\n",
       " 141,\n",
       " 142,\n",
       " 143,\n",
       " 144,\n",
       " 145,\n",
       " 146,\n",
       " 147,\n",
       " 148,\n",
       " 149,\n",
       " 150,\n",
       " 151,\n",
       " 152,\n",
       " 153,\n",
       " 154,\n",
       " 155,\n",
       " 156,\n",
       " 157,\n",
       " 158,\n",
       " 159,\n",
       " 160,\n",
       " 161,\n",
       " 162,\n",
       " 163,\n",
       " 164,\n",
       " 165,\n",
       " 166,\n",
       " 167,\n",
       " 168,\n",
       " 169,\n",
       " 170,\n",
       " 171,\n",
       " 172,\n",
       " 173,\n",
       " 174,\n",
       " 175,\n",
       " 176,\n",
       " 177,\n",
       " 178,\n",
       " 179,\n",
       " 180,\n",
       " 181,\n",
       " 182,\n",
       " 183,\n",
       " 184,\n",
       " 185,\n",
       " 186,\n",
       " 187,\n",
       " 188,\n",
       " 189,\n",
       " 190,\n",
       " 191,\n",
       " 192,\n",
       " 193,\n",
       " 194,\n",
       " 195,\n",
       " 196,\n",
       " 197,\n",
       " 198,\n",
       " 199,\n",
       " 200,\n",
       " 201,\n",
       " 202,\n",
       " 203,\n",
       " 204,\n",
       " 205,\n",
       " 206,\n",
       " 207,\n",
       " 208,\n",
       " 209,\n",
       " 210,\n",
       " 211,\n",
       " 212,\n",
       " 213,\n",
       " 214,\n",
       " 215,\n",
       " 216,\n",
       " 217,\n",
       " 218,\n",
       " 219,\n",
       " 220,\n",
       " 221,\n",
       " 222,\n",
       " 223,\n",
       " 224,\n",
       " 225,\n",
       " 226,\n",
       " 227,\n",
       " 228,\n",
       " 229,\n",
       " 230,\n",
       " 231,\n",
       " 232,\n",
       " 233,\n",
       " 234,\n",
       " 235,\n",
       " 236,\n",
       " 237,\n",
       " 238,\n",
       " 239,\n",
       " 240,\n",
       " 241,\n",
       " 242,\n",
       " 243,\n",
       " 244,\n",
       " 245,\n",
       " 246,\n",
       " 247,\n",
       " 248,\n",
       " 249,\n",
       " 250,\n",
       " 251,\n",
       " 252,\n",
       " 253,\n",
       " 254,\n",
       " 255,\n",
       " 256,\n",
       " 257,\n",
       " 258,\n",
       " 259,\n",
       " 260,\n",
       " 261,\n",
       " 262,\n",
       " 263,\n",
       " 264,\n",
       " 265,\n",
       " 266,\n",
       " 267,\n",
       " 268,\n",
       " 269,\n",
       " 270,\n",
       " 271,\n",
       " 272,\n",
       " 273,\n",
       " 274,\n",
       " 275,\n",
       " 276,\n",
       " 277,\n",
       " 278,\n",
       " 279,\n",
       " 280,\n",
       " 281,\n",
       " 282,\n",
       " 283,\n",
       " 284,\n",
       " 285,\n",
       " 286,\n",
       " 287,\n",
       " 288,\n",
       " 289,\n",
       " 290,\n",
       " 291,\n",
       " 292,\n",
       " 293,\n",
       " 294,\n",
       " 295,\n",
       " 296,\n",
       " 297,\n",
       " 298,\n",
       " 299,\n",
       " 300,\n",
       " 301,\n",
       " 302,\n",
       " 303,\n",
       " 304,\n",
       " 305,\n",
       " 306,\n",
       " 307,\n",
       " 308,\n",
       " 309,\n",
       " 310,\n",
       " 311,\n",
       " 312,\n",
       " 313,\n",
       " 314,\n",
       " 315,\n",
       " 316,\n",
       " 317,\n",
       " 318,\n",
       " 319,\n",
       " 320,\n",
       " 321,\n",
       " 322,\n",
       " 323,\n",
       " 324,\n",
       " 325,\n",
       " 326,\n",
       " 327,\n",
       " 328,\n",
       " 329,\n",
       " 330,\n",
       " 331,\n",
       " 332,\n",
       " 333,\n",
       " 334,\n",
       " 335,\n",
       " 336,\n",
       " 337,\n",
       " 338,\n",
       " 339,\n",
       " 340,\n",
       " 341,\n",
       " 342,\n",
       " 343,\n",
       " 344,\n",
       " 345,\n",
       " 346,\n",
       " 347,\n",
       " 348,\n",
       " 349,\n",
       " 350,\n",
       " 351,\n",
       " 352,\n",
       " 353,\n",
       " 354,\n",
       " 355,\n",
       " 356,\n",
       " 357,\n",
       " 358,\n",
       " 359,\n",
       " 360,\n",
       " 361,\n",
       " 362,\n",
       " 363,\n",
       " 364,\n",
       " 365,\n",
       " 366,\n",
       " 367,\n",
       " 368,\n",
       " 369,\n",
       " 370,\n",
       " 371,\n",
       " 372,\n",
       " 373,\n",
       " 374,\n",
       " 375,\n",
       " 376,\n",
       " 377,\n",
       " 378,\n",
       " 379,\n",
       " 380,\n",
       " 381,\n",
       " 382,\n",
       " 383,\n",
       " 384,\n",
       " 385,\n",
       " 386,\n",
       " 387,\n",
       " 388,\n",
       " 389,\n",
       " 390,\n",
       " 391,\n",
       " 392,\n",
       " 393,\n",
       " 394,\n",
       " 395,\n",
       " 396,\n",
       " 397,\n",
       " 398,\n",
       " 399,\n",
       " 400,\n",
       " 401,\n",
       " 402,\n",
       " 403,\n",
       " 404,\n",
       " 405,\n",
       " 406,\n",
       " 407,\n",
       " 408,\n",
       " 409,\n",
       " 410,\n",
       " 411,\n",
       " 412,\n",
       " 413,\n",
       " 414,\n",
       " 415,\n",
       " 416,\n",
       " 417,\n",
       " 418,\n",
       " 419,\n",
       " 420,\n",
       " 421,\n",
       " 422,\n",
       " 423,\n",
       " 424,\n",
       " 425,\n",
       " 426,\n",
       " 427,\n",
       " 428,\n",
       " 429,\n",
       " 430,\n",
       " 431,\n",
       " 432,\n",
       " 433,\n",
       " 434,\n",
       " 435,\n",
       " 436,\n",
       " 437,\n",
       " 438,\n",
       " 439,\n",
       " 440,\n",
       " 441,\n",
       " 442,\n",
       " 443,\n",
       " 444,\n",
       " 445,\n",
       " 446,\n",
       " 447,\n",
       " 448,\n",
       " 449,\n",
       " 450,\n",
       " 451,\n",
       " 452,\n",
       " 453,\n",
       " 454,\n",
       " 455,\n",
       " 456,\n",
       " 457,\n",
       " 458,\n",
       " 459,\n",
       " 460,\n",
       " 461,\n",
       " 462,\n",
       " 463,\n",
       " 464,\n",
       " 465,\n",
       " 466,\n",
       " 467,\n",
       " 468,\n",
       " 469,\n",
       " 470,\n",
       " 471,\n",
       " 472,\n",
       " 473,\n",
       " 474,\n",
       " 475,\n",
       " 476,\n",
       " 477,\n",
       " 478,\n",
       " 479,\n",
       " 480,\n",
       " 481,\n",
       " 482,\n",
       " 483,\n",
       " 484,\n",
       " 485,\n",
       " 486,\n",
       " 487,\n",
       " 488,\n",
       " 489,\n",
       " 490,\n",
       " 491,\n",
       " 492,\n",
       " 493,\n",
       " 494,\n",
       " 495,\n",
       " 496,\n",
       " 497,\n",
       " 498,\n",
       " 499,\n",
       " 500,\n",
       " 501,\n",
       " 502,\n",
       " 503,\n",
       " 504,\n",
       " 505,\n",
       " 506,\n",
       " 507,\n",
       " 508,\n",
       " 509,\n",
       " 510,\n",
       " 511,\n",
       " 512,\n",
       " 513,\n",
       " 514,\n",
       " 515,\n",
       " 516,\n",
       " 517,\n",
       " 518,\n",
       " 519,\n",
       " 520,\n",
       " 521,\n",
       " 522,\n",
       " 523,\n",
       " 524,\n",
       " 525,\n",
       " 526,\n",
       " 527,\n",
       " 528,\n",
       " 529,\n",
       " 530,\n",
       " 531,\n",
       " 532,\n",
       " 533,\n",
       " 534,\n",
       " 535,\n",
       " 536,\n",
       " 537,\n",
       " 538,\n",
       " 539,\n",
       " 540,\n",
       " 541,\n",
       " 542,\n",
       " 543,\n",
       " 544,\n",
       " 545,\n",
       " 546,\n",
       " 547,\n",
       " 548,\n",
       " 549,\n",
       " 550,\n",
       " 551,\n",
       " 552,\n",
       " 553,\n",
       " 554,\n",
       " 555,\n",
       " 556,\n",
       " 557,\n",
       " 558,\n",
       " 559,\n",
       " 560,\n",
       " 561,\n",
       " 562,\n",
       " 563,\n",
       " 564,\n",
       " 565,\n",
       " 566,\n",
       " 567,\n",
       " 568,\n",
       " 569,\n",
       " 570,\n",
       " 571,\n",
       " 572,\n",
       " 573,\n",
       " 574,\n",
       " 575,\n",
       " 576,\n",
       " 577,\n",
       " 578,\n",
       " 579,\n",
       " 580,\n",
       " 581,\n",
       " 582,\n",
       " 583,\n",
       " 584,\n",
       " 585,\n",
       " 586,\n",
       " 587,\n",
       " 588,\n",
       " 589,\n",
       " 590,\n",
       " 591,\n",
       " 592,\n",
       " 593,\n",
       " 594,\n",
       " 595,\n",
       " 596,\n",
       " 597,\n",
       " 598,\n",
       " 599,\n",
       " 600,\n",
       " 601,\n",
       " 602,\n",
       " 603,\n",
       " 604,\n",
       " 605,\n",
       " 606,\n",
       " 607,\n",
       " 608,\n",
       " 609,\n",
       " 610,\n",
       " 611,\n",
       " 612,\n",
       " 613,\n",
       " 614,\n",
       " 615,\n",
       " 616,\n",
       " 617,\n",
       " 618,\n",
       " 619,\n",
       " 620,\n",
       " 621,\n",
       " 622,\n",
       " 623,\n",
       " 624,\n",
       " 625,\n",
       " 626,\n",
       " 627,\n",
       " 628,\n",
       " 629,\n",
       " 630,\n",
       " 631,\n",
       " 632,\n",
       " 633,\n",
       " 634,\n",
       " 635,\n",
       " 636,\n",
       " 637,\n",
       " 638,\n",
       " 639,\n",
       " 640,\n",
       " 641,\n",
       " 642,\n",
       " 643,\n",
       " 644,\n",
       " 645,\n",
       " 646,\n",
       " 647,\n",
       " 648,\n",
       " 649,\n",
       " 650,\n",
       " 651,\n",
       " 652,\n",
       " 653,\n",
       " 654,\n",
       " 655,\n",
       " 656,\n",
       " 657,\n",
       " 658,\n",
       " 659,\n",
       " 660,\n",
       " 661,\n",
       " 662,\n",
       " 663,\n",
       " 664,\n",
       " 665,\n",
       " 666,\n",
       " 667,\n",
       " 668,\n",
       " 669,\n",
       " 670,\n",
       " 671,\n",
       " 672,\n",
       " 673,\n",
       " 674,\n",
       " 675,\n",
       " 676,\n",
       " 677,\n",
       " 678,\n",
       " 679,\n",
       " 680,\n",
       " 681,\n",
       " 682,\n",
       " 683,\n",
       " 684,\n",
       " 685,\n",
       " 686,\n",
       " 687,\n",
       " 688,\n",
       " 689,\n",
       " 690,\n",
       " 691,\n",
       " 692,\n",
       " 693,\n",
       " 694,\n",
       " 695,\n",
       " 696,\n",
       " 697,\n",
       " 698,\n",
       " 699,\n",
       " 700,\n",
       " 701,\n",
       " 702,\n",
       " 703,\n",
       " 704,\n",
       " 705,\n",
       " 706,\n",
       " 707,\n",
       " 708,\n",
       " 709,\n",
       " 710,\n",
       " 711,\n",
       " 712,\n",
       " 713,\n",
       " 714,\n",
       " 715,\n",
       " 716,\n",
       " 717,\n",
       " 718,\n",
       " 719,\n",
       " 720,\n",
       " 721,\n",
       " 722,\n",
       " 723,\n",
       " 724,\n",
       " 725,\n",
       " 726,\n",
       " 727,\n",
       " 728,\n",
       " 729,\n",
       " 730,\n",
       " 731,\n",
       " 732,\n",
       " 733,\n",
       " 734,\n",
       " 735,\n",
       " 736,\n",
       " 737,\n",
       " 738,\n",
       " 739,\n",
       " 740,\n",
       " 741,\n",
       " 742,\n",
       " 743,\n",
       " 744,\n",
       " 745,\n",
       " 746,\n",
       " 747,\n",
       " 748,\n",
       " 749,\n",
       " 750,\n",
       " 751,\n",
       " 752,\n",
       " 753,\n",
       " 754,\n",
       " 755,\n",
       " 756,\n",
       " 757,\n",
       " 758,\n",
       " 759,\n",
       " 760,\n",
       " 761,\n",
       " 762,\n",
       " 763,\n",
       " 764,\n",
       " 765,\n",
       " 766,\n",
       " 767,\n",
       " 768,\n",
       " 769,\n",
       " 770,\n",
       " 771,\n",
       " 772,\n",
       " 773,\n",
       " 774,\n",
       " 775,\n",
       " 776,\n",
       " 777,\n",
       " 778,\n",
       " 779,\n",
       " 780,\n",
       " 781,\n",
       " 782,\n",
       " 783,\n",
       " 784,\n",
       " 785,\n",
       " 786,\n",
       " 787,\n",
       " 788,\n",
       " 789,\n",
       " 790,\n",
       " 791,\n",
       " 792,\n",
       " 793,\n",
       " 794,\n",
       " 795,\n",
       " 796,\n",
       " 797,\n",
       " 798,\n",
       " 799,\n",
       " 800,\n",
       " 801,\n",
       " 802,\n",
       " 803,\n",
       " 804,\n",
       " 805,\n",
       " 806,\n",
       " 807,\n",
       " 808,\n",
       " 809,\n",
       " 810,\n",
       " 811,\n",
       " 812,\n",
       " 813,\n",
       " 814,\n",
       " 815,\n",
       " 816,\n",
       " 817,\n",
       " 818,\n",
       " 819,\n",
       " 820,\n",
       " 821,\n",
       " 822,\n",
       " 823,\n",
       " 824,\n",
       " 825,\n",
       " 826,\n",
       " 827,\n",
       " 828,\n",
       " 829,\n",
       " 830,\n",
       " 831,\n",
       " 832,\n",
       " 833,\n",
       " 834,\n",
       " 835,\n",
       " 836,\n",
       " 837,\n",
       " 838,\n",
       " 839,\n",
       " 840,\n",
       " 841,\n",
       " 842,\n",
       " 843,\n",
       " 844,\n",
       " 845,\n",
       " 846,\n",
       " 847,\n",
       " 848,\n",
       " 849,\n",
       " 850,\n",
       " 851,\n",
       " 852,\n",
       " 853,\n",
       " 854,\n",
       " 855,\n",
       " 856,\n",
       " 857,\n",
       " 858,\n",
       " 859,\n",
       " 860,\n",
       " 861,\n",
       " 862,\n",
       " 863,\n",
       " 864,\n",
       " 865,\n",
       " 866,\n",
       " 867,\n",
       " 868,\n",
       " 869,\n",
       " 870,\n",
       " 871,\n",
       " 872,\n",
       " 873,\n",
       " 874,\n",
       " 875,\n",
       " 876,\n",
       " 877,\n",
       " 878,\n",
       " 879,\n",
       " 880,\n",
       " 881,\n",
       " 882,\n",
       " 883,\n",
       " 884,\n",
       " 885,\n",
       " 886,\n",
       " 887,\n",
       " 888,\n",
       " 889,\n",
       " 890,\n",
       " 891,\n",
       " 892,\n",
       " 893,\n",
       " 894,\n",
       " 895,\n",
       " 896,\n",
       " 897,\n",
       " 898,\n",
       " 899,\n",
       " 900,\n",
       " 901,\n",
       " 902,\n",
       " 903,\n",
       " 904,\n",
       " 905,\n",
       " 906,\n",
       " 907,\n",
       " 908,\n",
       " 909,\n",
       " 910,\n",
       " 911,\n",
       " 912,\n",
       " 913,\n",
       " 914,\n",
       " 915,\n",
       " 916,\n",
       " 917,\n",
       " 918,\n",
       " 919,\n",
       " 920,\n",
       " 921,\n",
       " 922,\n",
       " 923,\n",
       " 924,\n",
       " 925,\n",
       " 926,\n",
       " 927,\n",
       " 928,\n",
       " 929,\n",
       " 930,\n",
       " 931,\n",
       " 932,\n",
       " 933,\n",
       " 934,\n",
       " 935,\n",
       " 936,\n",
       " 937,\n",
       " 938,\n",
       " 939,\n",
       " 940,\n",
       " 941,\n",
       " 942,\n",
       " 943,\n",
       " 944,\n",
       " 945,\n",
       " 946,\n",
       " 947,\n",
       " 948,\n",
       " 949,\n",
       " 950,\n",
       " 951,\n",
       " 952,\n",
       " 953,\n",
       " 954,\n",
       " 955,\n",
       " 956,\n",
       " 957,\n",
       " 958,\n",
       " 959,\n",
       " 960,\n",
       " 961,\n",
       " 962,\n",
       " 963,\n",
       " 964,\n",
       " 965,\n",
       " 966,\n",
       " 967,\n",
       " 968,\n",
       " 969,\n",
       " 970,\n",
       " 971,\n",
       " 972,\n",
       " 973,\n",
       " 974,\n",
       " 975,\n",
       " 976,\n",
       " 977,\n",
       " 978,\n",
       " 979,\n",
       " 980,\n",
       " 981,\n",
       " 982,\n",
       " 983,\n",
       " 984,\n",
       " 985,\n",
       " 986,\n",
       " 987,\n",
       " 988,\n",
       " 989,\n",
       " 990,\n",
       " 991,\n",
       " 992,\n",
       " 993,\n",
       " 994,\n",
       " 995,\n",
       " 996,\n",
       " 997,\n",
       " 998,\n",
       " 999,\n",
       " 1000,\n",
       " ...]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(phrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6027600d",
   "metadata": {},
   "source": [
    "## Training and Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "958799d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Processing_DF = pd.DataFrame(df.iloc[:10000,:])\n",
    "Processing_DF['Embeds'] = list(embeddings_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ab799fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Processing_DF.sample(frac=1)\n",
    "Processing_DF.sample(frac=1)\n",
    "Processing_DF.sample(frac=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(Processing_DF.drop(['Sentiment'],axis=1), list(Processing_DF['Sentiment']), test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e77b968",
   "metadata": {},
   "source": [
    "## Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0434699c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationModel:\n",
    "    def __init__(self, model_name=None, parameter_dict=None):\n",
    "        self.model_name = model_name\n",
    "        self.parameter_dict = parameter_dict\n",
    "        self.model = self.load_model()\n",
    "        \n",
    "    def load_model(self):            \n",
    "        if self.model_name in [\"Naive Bayes\", \"NB\"]:\n",
    "            from sklearn.naive_bayes import GaussianNB\n",
    "            return GaussianNB(**self.parameter_dict)\n",
    "\n",
    "        elif self.model_name in [\"Support Vector Machine\", \"SVC\"]:\n",
    "            from sklearn.svm import SVC\n",
    "            from sklearn.pipeline import make_pipeline\n",
    "            from sklearn.preprocessing import StandardScaler\n",
    "            return make_pipeline(StandardScaler(), SVC(**self.parameter_dict))\n",
    "\n",
    "        elif self.model_name in [\"Logistic Regression\", \"LR\"]:\n",
    "            from sklearn.linear_model import LogisticRegression\n",
    "            return LogisticRegression(**self.parameter_dict)\n",
    "\n",
    "        elif self.model_name in [\"Decision Tree\", \"DT\"]:\n",
    "            from sklearn.tree import DecisionTreeClassifier\n",
    "            return DecisionTreeClassifier(**self.parameter_dict)\n",
    "\n",
    "        elif self.model_name in [\"K Nearest Neighbour\", \"KNN\"]:\n",
    "            from sklearn.neighbors import KNeighborsClassifier\n",
    "            return KNeighborsClassifier(**self.parameter_dict)\n",
    "\n",
    "        elif self.model_name in [\"Multi Layer Perceptron\", \"ANN\"]:\n",
    "            from sklearn.neural_network import MLPClassifier\n",
    "            return MLPClassifier(**self.parameter_dict)\n",
    "\n",
    "        elif self.model_name in [\"Gradient Boosted Decision Tree\", \"GBDT\"]:\n",
    "            from sklearn.ensemble import GradientBoostingClassifier\n",
    "            return GradientBoostingClassifier(**self.parameter_dict)\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "    def fit(self, features, labels):\n",
    "        self.model = self.model.fit(features, labels)\n",
    "        \n",
    "    def predict(self, test_data):\n",
    "        return self.model.predict(test_data)\n",
    "    \n",
    "    def get_confusion_matrix(self, actual, prediction):\n",
    "        from sklearn.metrics import confusion_matrix\n",
    "        return confusion_matrix(actual,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5b4810b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ab6520",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "58911932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "\n",
      "[[  81   29    6    3    4]\n",
      " [ 189  201   84   36   26]\n",
      " [  93  323 1173  219   55]\n",
      " [  32   66  109  223  182]\n",
      " [   4    3    5   42  112]]\n",
      "\n",
      "1790\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.203     0.659     0.310       123\n",
      "           1      0.323     0.375     0.347       536\n",
      "           2      0.852     0.630     0.724      1863\n",
      "           3      0.426     0.364     0.393       612\n",
      "           4      0.296     0.675     0.411       166\n",
      "\n",
      "    accuracy                          0.542      3300\n",
      "   macro avg      0.420     0.540     0.437      3300\n",
      "weighted avg      0.635     0.542     0.570      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_naive_bayes = ClassificationModel(model_name=\"NB\", parameter_dict={})\n",
    "_naive_bayes.fit(np.array(X_train[\"Embeds\"].tolist()),y_train)\n",
    "_naive_bayes_predictions = _naive_bayes.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_naive_bayes_cm = _naive_bayes.get_confusion_matrix(y_test, _naive_bayes_predictions)\n",
    "print(\"CONFUSION MATRIX\\n\")\n",
    "print(_naive_bayes_cm)\n",
    "print(\"\\n\"+str(sum([_naive_bayes_cm[i][j] for i in range(len(_naive_bayes_cm)) for j in range(len(_naive_bayes_cm[i]))  if i==j]))+\"\\n\")\n",
    "print(metrics.classification_report(y_test, _naive_bayes_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e807f528",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bd049f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "\n",
      "[[  33   70   19    1    0]\n",
      " [  36  282  212    6    0]\n",
      " [   5  169 1554  128    7]\n",
      " [   0   27  242  297   46]\n",
      " [   0    0   16   93   57]]\n",
      "\n",
      "2223\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.446     0.268     0.335       123\n",
      "           1      0.515     0.526     0.520       536\n",
      "           2      0.761     0.834     0.796      1863\n",
      "           3      0.566     0.485     0.522       612\n",
      "           4      0.518     0.343     0.413       166\n",
      "\n",
      "    accuracy                          0.674      3300\n",
      "   macro avg      0.561     0.491     0.517      3300\n",
      "weighted avg      0.661     0.674     0.664      3300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91945\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "_logistic_regression = ClassificationModel(model_name=\"LR\", parameter_dict={'penalty':'l2'})\n",
    "_logistic_regression.fit(np.array(X_train[\"Embeds\"].tolist()),y_train)\n",
    "_logistic_regression_predictions = _logistic_regression.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_logistic_regression_cm = _logistic_regression.get_confusion_matrix(y_test, _logistic_regression_predictions)\n",
    "print(\"CONFUSION MATRIX\\n\")\n",
    "print(_logistic_regression_cm)\n",
    "print(\"\\n\"+str(sum([_logistic_regression_cm[i][j] for i in range(len(_logistic_regression_cm)) for j in range(len(_logistic_regression_cm[i]))  if i==j]))+\"\\n\")\n",
    "print(metrics.classification_report(y_test, _logistic_regression_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1c30c2fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "\n",
      "[[  66   52    2    3    0]\n",
      " [ 119  298   84   27    8]\n",
      " [  40  289 1223  273   38]\n",
      " [   8   47  121  308  128]\n",
      " [   0    2    6   61   97]]\n",
      "\n",
      "1992\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.283     0.537     0.371       123\n",
      "           1      0.433     0.556     0.487       536\n",
      "           2      0.852     0.656     0.741      1863\n",
      "           3      0.458     0.503     0.480       612\n",
      "           4      0.358     0.584     0.444       166\n",
      "\n",
      "    accuracy                          0.604      3300\n",
      "   macro avg      0.477     0.567     0.505      3300\n",
      "weighted avg      0.665     0.604     0.623      3300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91945\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "_logistic_regression = ClassificationModel(model_name=\"LR\", parameter_dict={'penalty':'l2','tol':0.00000001,'class_weight':'balanced'})\n",
    "_logistic_regression.fit(np.array(X_train[\"Embeds\"].tolist()),y_train)\n",
    "_logistic_regression_predictions = _logistic_regression.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_logistic_regression_cm = _logistic_regression.get_confusion_matrix(y_test, _logistic_regression_predictions)\n",
    "print(\"CONFUSION MATRIX\\n\")\n",
    "print(_logistic_regression_cm)\n",
    "print(\"\\n\"+str(sum([_logistic_regression_cm[i][j] for i in range(len(_logistic_regression_cm)) for j in range(len(_logistic_regression_cm[i]))  if i==j]))+\"\\n\")\n",
    "print(metrics.classification_report(y_test, _logistic_regression_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f071a3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "\n",
      "[[  33   69   20    1    0]\n",
      " [  38  280  208    9    1]\n",
      " [  10  156 1548  140    9]\n",
      " [   0   23  242  288   59]\n",
      " [   0    0   15   82   69]]\n",
      "\n",
      "2218\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.407     0.268     0.324       123\n",
      "           1      0.530     0.522     0.526       536\n",
      "           2      0.761     0.831     0.795      1863\n",
      "           3      0.554     0.471     0.509       612\n",
      "           4      0.500     0.416     0.454       166\n",
      "\n",
      "    accuracy                          0.672      3300\n",
      "   macro avg      0.551     0.502     0.521      3300\n",
      "weighted avg      0.659     0.672     0.663      3300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91945\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    }
   ],
   "source": [
    "_logistic_regression = ClassificationModel(model_name=\"LR\", parameter_dict={'penalty':'l2','tol':0.00000001,'solver':'saga'})\n",
    "_logistic_regression.fit(np.array(X_train[\"Embeds\"].tolist()),y_train)\n",
    "_logistic_regression_predictions = _logistic_regression.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_logistic_regression_cm = _logistic_regression.get_confusion_matrix(y_test, _logistic_regression_predictions)\n",
    "print(\"CONFUSION MATRIX\\n\")\n",
    "print(_logistic_regression_cm)\n",
    "print(\"\\n\"+str(sum([_logistic_regression_cm[i][j] for i in range(len(_logistic_regression_cm)) for j in range(len(_logistic_regression_cm[i]))  if i==j]))+\"\\n\")\n",
    "print(metrics.classification_report(y_test, _logistic_regression_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f72304b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "\n",
      "[[  39   63   20    1    0]\n",
      " [  49  258  218   10    1]\n",
      " [  13  145 1558  138    9]\n",
      " [   0   23  244  273   72]\n",
      " [   0    0   15   81   70]]\n",
      "\n",
      "2198\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.386     0.317     0.348       123\n",
      "           1      0.528     0.481     0.503       536\n",
      "           2      0.758     0.836     0.795      1863\n",
      "           3      0.543     0.446     0.490       612\n",
      "           4      0.461     0.422     0.440       166\n",
      "\n",
      "    accuracy                          0.666      3300\n",
      "   macro avg      0.535     0.500     0.515      3300\n",
      "weighted avg      0.652     0.666     0.657      3300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91945\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    }
   ],
   "source": [
    "_logistic_regression = ClassificationModel(model_name=\"LR\", parameter_dict={'penalty':'l2','tol':0.00000001,'solver':'sag'})\n",
    "_logistic_regression.fit(np.array(X_train[\"Embeds\"].tolist()),y_train)\n",
    "_logistic_regression_predictions = _logistic_regression.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_logistic_regression_cm = _logistic_regression.get_confusion_matrix(y_test, _logistic_regression_predictions)\n",
    "print(\"CONFUSION MATRIX\\n\")\n",
    "print(_logistic_regression_cm)\n",
    "print(\"\\n\"+str(sum([_logistic_regression_cm[i][j] for i in range(len(_logistic_regression_cm)) for j in range(len(_logistic_regression_cm[i]))  if i==j]))+\"\\n\")\n",
    "print(metrics.classification_report(y_test, _logistic_regression_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "44ffe8eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "\n",
      "[[  29   76   17    1    0]\n",
      " [  27  277  222   10    0]\n",
      " [   8  139 1586  127    3]\n",
      " [   0   22  255  297   38]\n",
      " [   0    0   16   89   61]]\n",
      "\n",
      "2250\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.453     0.236     0.310       123\n",
      "           1      0.539     0.517     0.528       536\n",
      "           2      0.757     0.851     0.801      1863\n",
      "           3      0.567     0.485     0.523       612\n",
      "           4      0.598     0.367     0.455       166\n",
      "\n",
      "    accuracy                          0.682      3300\n",
      "   macro avg      0.583     0.491     0.523      3300\n",
      "weighted avg      0.667     0.682     0.669      3300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91945\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "_logistic_regression = ClassificationModel(model_name=\"LR\", parameter_dict={'penalty':'l1','tol':0.00000001, 'solver':'liblinear'})\n",
    "_logistic_regression.fit(np.array(X_train[\"Embeds\"].tolist()),y_train)\n",
    "_logistic_regression_predictions = _logistic_regression.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_logistic_regression_cm = _logistic_regression.get_confusion_matrix(y_test, _logistic_regression_predictions)\n",
    "print(\"CONFUSION MATRIX\\n\")\n",
    "print(_logistic_regression_cm)\n",
    "print(\"\\n\"+str(sum([_logistic_regression_cm[i][j] for i in range(len(_logistic_regression_cm)) for j in range(len(_logistic_regression_cm[i]))  if i==j]))+\"\\n\")\n",
    "print(metrics.classification_report(y_test, _logistic_regression_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f7e23009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "\n",
      "[[  33   68   21    1    0]\n",
      " [  45  272  207   11    1]\n",
      " [  12  159 1543  139   10]\n",
      " [   0   19  243  288   62]\n",
      " [   0    0   14   88   64]]\n",
      "\n",
      "2200\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.367     0.268     0.310       123\n",
      "           1      0.525     0.507     0.516       536\n",
      "           2      0.761     0.828     0.793      1863\n",
      "           3      0.546     0.471     0.506       612\n",
      "           4      0.467     0.386     0.422       166\n",
      "\n",
      "    accuracy                          0.667      3300\n",
      "   macro avg      0.533     0.492     0.509      3300\n",
      "weighted avg      0.653     0.667     0.658      3300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91945\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\91945\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:195: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n"
     ]
    }
   ],
   "source": [
    "_logistic_regression = ClassificationModel(model_name=\"LR\", parameter_dict={'penalty':'l2','tol':0.00000001, 'solver':'newton-cg'})\n",
    "_logistic_regression.fit(np.array(X_train[\"Embeds\"].tolist()),y_train)\n",
    "_logistic_regression_predictions = _logistic_regression.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_logistic_regression_cm = _logistic_regression.get_confusion_matrix(y_test, _logistic_regression_predictions)\n",
    "print(\"CONFUSION MATRIX\\n\")\n",
    "print(_logistic_regression_cm)\n",
    "print(\"\\n\"+str(sum([_logistic_regression_cm[i][j] for i in range(len(_logistic_regression_cm)) for j in range(len(_logistic_regression_cm[i]))  if i==j]))+\"\\n\")\n",
    "print(metrics.classification_report(y_test, _logistic_regression_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d5455a",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6592be09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "\n",
      "[[  19   89   14    1    0]\n",
      " [  10  298  218   10    0]\n",
      " [   4  118 1655   86    0]\n",
      " [   0   17  267  315   13]\n",
      " [   0    1   20  117   28]]\n",
      "\n",
      "2315\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.576     0.154     0.244       123\n",
      "           1      0.570     0.556     0.563       536\n",
      "           2      0.761     0.888     0.820      1863\n",
      "           3      0.595     0.515     0.552       612\n",
      "           4      0.683     0.169     0.271       166\n",
      "\n",
      "    accuracy                          0.702      3300\n",
      "   macro avg      0.637     0.456     0.490      3300\n",
      "weighted avg      0.689     0.702     0.679      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_svc_classification = ClassificationModel(model_name=\"SVC\", parameter_dict={})\n",
    "_svc_classification.fit(np.array(X_train[\"Embeds\"].tolist()),y_train)\n",
    "_svc_classification_predictions = _svc_classification.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_svc_classification_cm = _svc_classification.get_confusion_matrix(y_test, _svc_classification_predictions)\n",
    "print(\"CONFUSION MATRIX\\n\")\n",
    "print(_svc_classification_cm)\n",
    "print(\"\\n\"+str(sum([_svc_classification_cm[i][j] for i in range(len(_svc_classification_cm)) for j in range(len(_svc_classification_cm[i]))  if i==j]))+\"\\n\")\n",
    "print(metrics.classification_report(y_test, _svc_classification_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "25ba5e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "\n",
      "[[  26   82   14    1    0]\n",
      " [  21  280  228    7    0]\n",
      " [   5  118 1648   91    1]\n",
      " [   0   11  284  297   20]\n",
      " [   0    1   18  109   38]]\n",
      "\n",
      "2289\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.500     0.211     0.297       123\n",
      "           1      0.569     0.522     0.545       536\n",
      "           2      0.752     0.885     0.813      1863\n",
      "           3      0.588     0.485     0.532       612\n",
      "           4      0.644     0.229     0.338       166\n",
      "\n",
      "    accuracy                          0.694      3300\n",
      "   macro avg      0.611     0.467     0.505      3300\n",
      "weighted avg      0.677     0.694     0.674      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_svc_classification = ClassificationModel(model_name=\"SVC\", parameter_dict={'kernel':'poly'})\n",
    "_svc_classification.fit(np.array(X_train[\"Embeds\"].tolist()),y_train)\n",
    "_svc_classification_predictions = _svc_classification.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_svc_classification_cm = _svc_classification.get_confusion_matrix(y_test, _svc_classification_predictions)\n",
    "print(\"CONFUSION MATRIX\\n\")\n",
    "print(_svc_classification_cm)\n",
    "print(\"\\n\"+str(sum([_svc_classification_cm[i][j] for i in range(len(_svc_classification_cm)) for j in range(len(_svc_classification_cm[i]))  if i==j]))+\"\\n\")\n",
    "print(metrics.classification_report(y_test, _svc_classification_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b60cefd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "\n",
      "[[   3   78   36    6    0]\n",
      " [   7  236  268   25    0]\n",
      " [   2  171 1530  159    1]\n",
      " [   0   38  281  280   13]\n",
      " [   1    3   39  111   12]]\n",
      "\n",
      "2061\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.231     0.024     0.044       123\n",
      "           1      0.449     0.440     0.444       536\n",
      "           2      0.710     0.821     0.762      1863\n",
      "           3      0.482     0.458     0.469       612\n",
      "           4      0.462     0.072     0.125       166\n",
      "\n",
      "    accuracy                          0.625      3300\n",
      "   macro avg      0.467     0.363     0.369      3300\n",
      "weighted avg      0.595     0.625     0.597      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_svc_classification = ClassificationModel(model_name=\"SVC\", parameter_dict={'kernel':'sigmoid'})\n",
    "_svc_classification.fit(np.array(X_train[\"Embeds\"].tolist()),y_train)\n",
    "_svc_classification_predictions = _svc_classification.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_svc_classification_cm = _svc_classification.get_confusion_matrix(y_test, _svc_classification_predictions)\n",
    "print(\"CONFUSION MATRIX\\n\")\n",
    "print(_svc_classification_cm)\n",
    "print(\"\\n\"+str(sum([_svc_classification_cm[i][j] for i in range(len(_svc_classification_cm)) for j in range(len(_svc_classification_cm[i]))  if i==j]))+\"\\n\")\n",
    "print(metrics.classification_report(y_test, _svc_classification_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6b2bfd95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "\n",
      "[[  26   82   14    1    0]\n",
      " [  21  280  228    7    0]\n",
      " [   5  118 1648   91    1]\n",
      " [   0   11  284  297   20]\n",
      " [   0    1   18  109   38]]\n",
      "\n",
      "2289\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.500     0.211     0.297       123\n",
      "           1      0.569     0.522     0.545       536\n",
      "           2      0.752     0.885     0.813      1863\n",
      "           3      0.588     0.485     0.532       612\n",
      "           4      0.644     0.229     0.338       166\n",
      "\n",
      "    accuracy                          0.694      3300\n",
      "   macro avg      0.611     0.467     0.505      3300\n",
      "weighted avg      0.677     0.694     0.674      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_svc_classification = ClassificationModel(model_name=\"SVC\", parameter_dict={'kernel':'poly','gamma':'auto'})\n",
    "_svc_classification.fit(np.array(X_train[\"Embeds\"].tolist()),y_train)\n",
    "_svc_classification_predictions = _svc_classification.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_svc_classification_cm = _svc_classification.get_confusion_matrix(y_test, _svc_classification_predictions)\n",
    "print(\"CONFUSION MATRIX\\n\")\n",
    "print(_svc_classification_cm)\n",
    "print(\"\\n\"+str(sum([_svc_classification_cm[i][j] for i in range(len(_svc_classification_cm)) for j in range(len(_svc_classification_cm[i]))  if i==j]))+\"\\n\")\n",
    "print(metrics.classification_report(y_test, _svc_classification_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5556d415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "\n",
      "[[  19   89   14    1    0]\n",
      " [  10  298  218   10    0]\n",
      " [   4  118 1655   86    0]\n",
      " [   0   17  267  315   13]\n",
      " [   0    1   20  117   28]]\n",
      "\n",
      "2315\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.576     0.154     0.244       123\n",
      "           1      0.570     0.556     0.563       536\n",
      "           2      0.761     0.888     0.820      1863\n",
      "           3      0.595     0.515     0.552       612\n",
      "           4      0.683     0.169     0.271       166\n",
      "\n",
      "    accuracy                          0.702      3300\n",
      "   macro avg      0.637     0.456     0.490      3300\n",
      "weighted avg      0.689     0.702     0.679      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_svc_classification = ClassificationModel(model_name=\"SVC\", parameter_dict={'gamma':'auto'})\n",
    "_svc_classification.fit(np.array(X_train[\"Embeds\"].tolist()),y_train)\n",
    "_svc_classification_predictions = _svc_classification.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_svc_classification_cm = _svc_classification.get_confusion_matrix(y_test, _svc_classification_predictions)\n",
    "print(\"CONFUSION MATRIX\\n\")\n",
    "print(_svc_classification_cm)\n",
    "print(\"\\n\"+str(sum([_svc_classification_cm[i][j] for i in range(len(_svc_classification_cm)) for j in range(len(_svc_classification_cm[i]))  if i==j]))+\"\\n\")\n",
    "print(metrics.classification_report(y_test, _svc_classification_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3597a16c",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d1ba4870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "\n",
      "[[  48   61   13    1    0]\n",
      " [  88  272  165   10    1]\n",
      " [  32  175 1530  120    6]\n",
      " [  11   34  263  261   43]\n",
      " [   1    4   23   82   56]]\n",
      "\n",
      "2167\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.267     0.390     0.317       123\n",
      "           1      0.498     0.507     0.503       536\n",
      "           2      0.767     0.821     0.793      1863\n",
      "           3      0.551     0.426     0.481       612\n",
      "           4      0.528     0.337     0.412       166\n",
      "\n",
      "    accuracy                          0.657      3300\n",
      "   macro avg      0.522     0.497     0.501      3300\n",
      "weighted avg      0.653     0.657     0.651      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_knn_classification = ClassificationModel(model_name=\"KNN\", parameter_dict={'n_neighbors':3})\n",
    "_knn_classification.fit(np.array(X_train[\"Embeds\"].tolist()), y_train)\n",
    "_knn_classification_predictions = _knn_classification.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_knn_classification_cm = _knn_classification.get_confusion_matrix(y_test, list(_knn_classification_predictions))\n",
    "print(\"CONFUSION MATRIX\\n\")\n",
    "print(_knn_classification_cm)\n",
    "print(\"\\n\"+str(sum([_knn_classification_cm[i][j] for i in range(len(_knn_classification_cm)) for j in range(len(_knn_classification_cm[i]))  if i==j]))+\"\\n\")\n",
    "print(metrics.classification_report(y_test, _knn_classification_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c5ae769e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "\n",
      "[[  33   75   14    1    0]\n",
      " [  38  294  191   12    1]\n",
      " [  15  133 1579  133    3]\n",
      " [   2   19  250  295   46]\n",
      " [   0    0   19   93   54]]\n",
      "\n",
      "2255\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.375     0.268     0.313       123\n",
      "           1      0.564     0.549     0.556       536\n",
      "           2      0.769     0.848     0.806      1863\n",
      "           3      0.552     0.482     0.515       612\n",
      "           4      0.519     0.325     0.400       166\n",
      "\n",
      "    accuracy                          0.683      3300\n",
      "   macro avg      0.556     0.494     0.518      3300\n",
      "weighted avg      0.668     0.683     0.673      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_knn_classification = ClassificationModel(model_name=\"KNN\", parameter_dict={'n_neighbors':7,'weights':'distance'})\n",
    "_knn_classification.fit(np.array(X_train[\"Embeds\"].tolist()), y_train)\n",
    "_knn_classification_predictions = _knn_classification.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_knn_classification_cm = _knn_classification.get_confusion_matrix(y_test, list(_knn_classification_predictions))\n",
    "print(\"CONFUSION MATRIX\\n\")\n",
    "print(_knn_classification_cm)\n",
    "print(\"\\n\"+str(sum([_knn_classification_cm[i][j] for i in range(len(_knn_classification_cm)) for j in range(len(_knn_classification_cm[i]))  if i==j]))+\"\\n\")\n",
    "print(metrics.classification_report(y_test, _knn_classification_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b3d9eb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "\n",
      "[[  33   75   14    1    0]\n",
      " [  38  294  191   12    1]\n",
      " [  15  133 1579  133    3]\n",
      " [   2   19  250  295   46]\n",
      " [   0    0   19   93   54]]\n",
      "\n",
      "2255\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.375     0.268     0.313       123\n",
      "           1      0.564     0.549     0.556       536\n",
      "           2      0.769     0.848     0.806      1863\n",
      "           3      0.552     0.482     0.515       612\n",
      "           4      0.519     0.325     0.400       166\n",
      "\n",
      "    accuracy                          0.683      3300\n",
      "   macro avg      0.556     0.494     0.518      3300\n",
      "weighted avg      0.668     0.683     0.673      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_knn_classification = ClassificationModel(model_name=\"KNN\", parameter_dict={'n_neighbors':7,'weights':'distance','algorithm':'kd_tree'})\n",
    "_knn_classification.fit(np.array(X_train[\"Embeds\"].tolist()), y_train)\n",
    "_knn_classification_predictions = _knn_classification.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_knn_classification_cm = _knn_classification.get_confusion_matrix(y_test, list(_knn_classification_predictions))\n",
    "print(\"CONFUSION MATRIX\\n\")\n",
    "print(_knn_classification_cm)\n",
    "print(\"\\n\"+str(sum([_knn_classification_cm[i][j] for i in range(len(_knn_classification_cm)) for j in range(len(_knn_classification_cm[i]))  if i==j]))+\"\\n\")\n",
    "print(metrics.classification_report(y_test, _knn_classification_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "dc5ec3a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "\n",
      "[[  36   72   14    1    0]\n",
      " [  42  289  191   12    2]\n",
      " [  15  142 1572  131    3]\n",
      " [   2   20  248  294   48]\n",
      " [   0    1   18   93   54]]\n",
      "\n",
      "2245\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.379     0.293     0.330       123\n",
      "           1      0.552     0.539     0.545       536\n",
      "           2      0.769     0.844     0.805      1863\n",
      "           3      0.554     0.480     0.514       612\n",
      "           4      0.505     0.325     0.396       166\n",
      "\n",
      "    accuracy                          0.680      3300\n",
      "   macro avg      0.552     0.496     0.518      3300\n",
      "weighted avg      0.666     0.680     0.671      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_knn_classification = ClassificationModel(model_name=\"KNN\", parameter_dict={'p':1, 'n_neighbors':7,'weights':'distance','algorithm':'kd_tree'})\n",
    "_knn_classification.fit(np.array(X_train[\"Embeds\"].tolist()), y_train)\n",
    "_knn_classification_predictions = _knn_classification.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_knn_classification_cm = _knn_classification.get_confusion_matrix(y_test, list(_knn_classification_predictions))\n",
    "print(\"CONFUSION MATRIX\\n\")\n",
    "print(_knn_classification_cm)\n",
    "print(\"\\n\"+str(sum([_knn_classification_cm[i][j] for i in range(len(_knn_classification_cm)) for j in range(len(_knn_classification_cm[i]))  if i==j]))+\"\\n\")\n",
    "print(metrics.classification_report(y_test, _knn_classification_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "41780995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "\n",
      "[[  33   75   14    1    0]\n",
      " [  38  294  191   12    1]\n",
      " [  15  133 1579  133    3]\n",
      " [   2   19  250  295   46]\n",
      " [   0    0   19   93   54]]\n",
      "\n",
      "2255\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.375     0.268     0.313       123\n",
      "           1      0.564     0.549     0.556       536\n",
      "           2      0.769     0.848     0.806      1863\n",
      "           3      0.552     0.482     0.515       612\n",
      "           4      0.519     0.325     0.400       166\n",
      "\n",
      "    accuracy                          0.683      3300\n",
      "   macro avg      0.556     0.494     0.518      3300\n",
      "weighted avg      0.668     0.683     0.673      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_knn_classification = ClassificationModel(model_name=\"KNN\", parameter_dict={'n_neighbors':7,'weights':'distance','algorithm':'ball_tree'})\n",
    "_knn_classification.fit(np.array(X_train[\"Embeds\"].tolist()), y_train)\n",
    "_knn_classification_predictions = _knn_classification.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_knn_classification_cm = _knn_classification.get_confusion_matrix(y_test, list(_knn_classification_predictions))\n",
    "print(\"CONFUSION MATRIX\\n\")\n",
    "print(_knn_classification_cm)\n",
    "print(\"\\n\"+str(sum([_knn_classification_cm[i][j] for i in range(len(_knn_classification_cm)) for j in range(len(_knn_classification_cm[i]))  if i==j]))+\"\\n\")\n",
    "print(metrics.classification_report(y_test, _knn_classification_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1d449fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "\n",
      "[[  36   72   14    1    0]\n",
      " [  42  289  191   12    2]\n",
      " [  15  142 1572  131    3]\n",
      " [   2   20  248  294   48]\n",
      " [   0    1   18   93   54]]\n",
      "\n",
      "2245\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.379     0.293     0.330       123\n",
      "           1      0.552     0.539     0.545       536\n",
      "           2      0.769     0.844     0.805      1863\n",
      "           3      0.554     0.480     0.514       612\n",
      "           4      0.505     0.325     0.396       166\n",
      "\n",
      "    accuracy                          0.680      3300\n",
      "   macro avg      0.552     0.496     0.518      3300\n",
      "weighted avg      0.666     0.680     0.671      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_knn_classification = ClassificationModel(model_name=\"KNN\", parameter_dict={'p':1, 'n_neighbors':7,'weights':'distance','algorithm':'ball_tree'})\n",
    "_knn_classification.fit(np.array(X_train[\"Embeds\"].tolist()), y_train)\n",
    "_knn_classification_predictions = _knn_classification.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_knn_classification_cm = _knn_classification.get_confusion_matrix(y_test, list(_knn_classification_predictions))\n",
    "print(\"CONFUSION MATRIX\\n\")\n",
    "print(_knn_classification_cm)\n",
    "print(\"\\n\"+str(sum([_knn_classification_cm[i][j] for i in range(len(_knn_classification_cm)) for j in range(len(_knn_classification_cm[i]))  if i==j]))+\"\\n\")\n",
    "print(metrics.classification_report(y_test, _knn_classification_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "433fec25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "\n",
      "[[  36   71   15    1    0]\n",
      " [  37  281  205   13    0]\n",
      " [  12  130 1596  123    2]\n",
      " [   1   21  245  302   43]\n",
      " [   1    1   16   99   49]]\n",
      "\n",
      "2264\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.414     0.293     0.343       123\n",
      "           1      0.558     0.524     0.540       536\n",
      "           2      0.768     0.857     0.810      1863\n",
      "           3      0.561     0.493     0.525       612\n",
      "           4      0.521     0.295     0.377       166\n",
      "\n",
      "    accuracy                          0.686      3300\n",
      "   macro avg      0.564     0.492     0.519      3300\n",
      "weighted avg      0.670     0.686     0.674      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_knn_classification = ClassificationModel(model_name=\"KNN\", parameter_dict={'n_neighbors':10,'weights':'distance','p':1})\n",
    "_knn_classification.fit(np.array(X_train[\"Embeds\"].tolist()), y_train)\n",
    "_knn_classification_predictions = _knn_classification.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_knn_classification_cm = _knn_classification.get_confusion_matrix(y_test, list(_knn_classification_predictions))\n",
    "print(\"CONFUSION MATRIX\\n\")\n",
    "print(_knn_classification_cm)\n",
    "print(\"\\n\"+str(sum([_knn_classification_cm[i][j] for i in range(len(_knn_classification_cm)) for j in range(len(_knn_classification_cm[i]))  if i==j]))+\"\\n\")\n",
    "print(metrics.classification_report(y_test, _knn_classification_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb10941e",
   "metadata": {},
   "source": [
    "## Gradient Boosted Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a0f5707f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "\n",
      "[[  28   71   22    2    0]\n",
      " [  22  265  225   23    1]\n",
      " [   6  114 1631  110    2]\n",
      " [   1   21  262  299   29]\n",
      " [   0    2   16  110   38]]\n",
      "\n",
      "2261\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.491     0.228     0.311       123\n",
      "           1      0.560     0.494     0.525       536\n",
      "           2      0.756     0.875     0.812      1863\n",
      "           3      0.550     0.489     0.517       612\n",
      "           4      0.543     0.229     0.322       166\n",
      "\n",
      "    accuracy                          0.685      3300\n",
      "   macro avg      0.580     0.463     0.497      3300\n",
      "weighted avg      0.666     0.685     0.667      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_gbdt_classification = ClassificationModel(model_name=\"GBDT\", parameter_dict={})\n",
    "_gbdt_classification.fit(np.array(X_train[\"Embeds\"].tolist()), y_train)\n",
    "_gbdt_classification_predictions = _gbdt_classification.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_gbdt_classification_cm = _gbdt_classification.get_confusion_matrix(y_test, list(_gbdt_classification_predictions))\n",
    "print(\"CONFUSION MATRIX\\n\")\n",
    "print(_gbdt_classification_cm)\n",
    "print(\"\\n\"+str(sum([_gbdt_classification_cm[i][j] for i in range(len(_gbdt_classification_cm)) for j in range(len(_gbdt_classification_cm[i]))  if i==j]))+\"\\n\")\n",
    "print(metrics.classification_report(y_test, _gbdt_classification_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e149ccbc",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6af9e18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "\n",
      "[[  40   52   24    7    0]\n",
      " [  48  226  221   37    4]\n",
      " [  28  213 1335  247   40]\n",
      " [   3   43  258  228   80]\n",
      " [   0    6   39   78   43]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.336     0.325     0.331       123\n",
      "           1      0.419     0.422     0.420       536\n",
      "           2      0.711     0.717     0.714      1863\n",
      "           3      0.382     0.373     0.377       612\n",
      "           4      0.257     0.259     0.258       166\n",
      "\n",
      "    accuracy                          0.567      3300\n",
      "   macro avg      0.421     0.419     0.420      3300\n",
      "weighted avg      0.566     0.567     0.567      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_dt_classification = ClassificationModel(model_name=\"DT\", parameter_dict={})\n",
    "_dt_classification.fit(np.array(X_train[\"Embeds\"].tolist()), y_train)\n",
    "_dt_classification_predictions = _dt_classification.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "print(\"CONFUSION MATRIX\\n\")\n",
    "_dt_classification_cm = _dt_classification.get_confusion_matrix(y_test, list(_dt_classification_predictions))\n",
    "print(_dt_classification_cm)\n",
    "print(\"\\n\")\n",
    "print(metrics.classification_report(y_test, _dt_classification_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8e01160e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "\n",
      "[[  33   57   24    8    1]\n",
      " [  54  232  211   35    4]\n",
      " [  32  208 1362  241   20]\n",
      " [   8   48  231  267   58]\n",
      " [   0   10   28   86   42]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.260     0.268     0.264       123\n",
      "           1      0.418     0.433     0.425       536\n",
      "           2      0.734     0.731     0.732      1863\n",
      "           3      0.419     0.436     0.428       612\n",
      "           4      0.336     0.253     0.289       166\n",
      "\n",
      "    accuracy                          0.587      3300\n",
      "   macro avg      0.433     0.424     0.428      3300\n",
      "weighted avg      0.587     0.587     0.586      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_dt_classification = ClassificationModel(model_name=\"DT\", parameter_dict={'criterion':'entropy'})\n",
    "_dt_classification.fit(np.array(X_train[\"Embeds\"].tolist()), y_train)\n",
    "_dt_classification_predictions = _dt_classification.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "print(\"CONFUSION MATRIX\\n\")\n",
    "_dt_classification_cm = _dt_classification.get_confusion_matrix(y_test, list(_dt_classification_predictions))\n",
    "print(_dt_classification_cm)\n",
    "print(\"\\n\")\n",
    "print(metrics.classification_report(y_test, _dt_classification_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9ed996a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "\n",
      "[[   8   64   48    3    0]\n",
      " [  10  208  299   19    0]\n",
      " [   6  145 1609  103    0]\n",
      " [   0   43  325  244    0]\n",
      " [   0   13   50  103    0]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.333     0.065     0.109       123\n",
      "           1      0.440     0.388     0.412       536\n",
      "           2      0.690     0.864     0.767      1863\n",
      "           3      0.517     0.399     0.450       612\n",
      "           4      0.000     0.000     0.000       166\n",
      "\n",
      "    accuracy                          0.627      3300\n",
      "   macro avg      0.396     0.343     0.348      3300\n",
      "weighted avg      0.569     0.627     0.588      3300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91945\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\91945\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\91945\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "_dt_classification = ClassificationModel(model_name=\"DT\", parameter_dict={'max_depth':5})\n",
    "_dt_classification.fit(np.array(X_train[\"Embeds\"].tolist()), y_train)\n",
    "_dt_classification_predictions = _dt_classification.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "print(\"CONFUSION MATRIX\\n\")\n",
    "_dt_classification_cm = _dt_classification.get_confusion_matrix(y_test, list(_dt_classification_predictions))\n",
    "print(_dt_classification_cm)\n",
    "print(\"\\n\")\n",
    "print(metrics.classification_report(y_test, _dt_classification_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ad53f9",
   "metadata": {},
   "source": [
    "## Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a6be5c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "\n",
      "[[  43   64   13    2    1]\n",
      " [  55  267  192   19    3]\n",
      " [  15  163 1441  238    6]\n",
      " [   2   14  217  316   63]\n",
      " [   1    0   17   96   52]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.371     0.350     0.360       123\n",
      "           1      0.526     0.498     0.511       536\n",
      "           2      0.766     0.773     0.770      1863\n",
      "           3      0.471     0.516     0.493       612\n",
      "           4      0.416     0.313     0.357       166\n",
      "\n",
      "    accuracy                          0.642      3300\n",
      "   macro avg      0.510     0.490     0.498      3300\n",
      "weighted avg      0.640     0.642     0.641      3300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91945\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "_ann_classification = ClassificationModel(model_name=\"ANN\", parameter_dict={})\n",
    "_ann_classification.fit(np.array(X_train[\"Embeds\"].tolist()), y_train)\n",
    "_ann_classification_predictions = _ann_classification.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_ann_classification_cm = _ann_classification.get_confusion_matrix(y_test, list(_ann_classification_predictions))\n",
    "print(\"CONFUSION MATRIX\\n\")\n",
    "print(_ann_classification_cm)\n",
    "print(\"\\n\")\n",
    "print(metrics.classification_report(y_test, _ann_classification_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "636f6242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "\n",
      "[[  38   67   17    1    0]\n",
      " [  40  304  173   17    2]\n",
      " [  12  169 1487  194    1]\n",
      " [   0   20  214  339   39]\n",
      " [   0    0   12  112   42]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.422     0.309     0.357       123\n",
      "           1      0.543     0.567     0.555       536\n",
      "           2      0.781     0.798     0.790      1863\n",
      "           3      0.511     0.554     0.532       612\n",
      "           4      0.500     0.253     0.336       166\n",
      "\n",
      "    accuracy                          0.670      3300\n",
      "   macro avg      0.552     0.496     0.514      3300\n",
      "weighted avg      0.665     0.670     0.665      3300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91945\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "_ann_classification = ClassificationModel(model_name=\"ANN\", parameter_dict={'activation':'tanh'})\n",
    "_ann_classification.fit(np.array(X_train[\"Embeds\"].tolist()), y_train)\n",
    "_ann_classification_predictions = _ann_classification.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_ann_classification_cm = _ann_classification.get_confusion_matrix(y_test, list(_ann_classification_predictions))\n",
    "print(\"CONFUSION MATRIX\\n\")\n",
    "print(_ann_classification_cm)\n",
    "print(\"\\n\")\n",
    "print(metrics.classification_report(y_test, _ann_classification_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ec83ee00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "\n",
      "[[  19   82   21    1    0]\n",
      " [  20  263  240   10    3]\n",
      " [   2  119 1645   95    2]\n",
      " [   1   21  276  281   33]\n",
      " [   0    2   18   90   56]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.452     0.154     0.230       123\n",
      "           1      0.540     0.491     0.514       536\n",
      "           2      0.748     0.883     0.810      1863\n",
      "           3      0.589     0.459     0.516       612\n",
      "           4      0.596     0.337     0.431       166\n",
      "\n",
      "    accuracy                          0.686      3300\n",
      "   macro avg      0.585     0.465     0.500      3300\n",
      "weighted avg      0.666     0.686     0.667      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ann_classification = ClassificationModel(model_name=\"ANN\", parameter_dict={'early_stopping':True})\n",
    "_ann_classification.fit(np.array(X_train[\"Embeds\"].tolist()), y_train)\n",
    "_ann_classification_predictions = _ann_classification.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_ann_classification_cm = _ann_classification.get_confusion_matrix(y_test, list(_ann_classification_predictions))\n",
    "print(\"CONFUSION MATRIX\\n\")\n",
    "print(_ann_classification_cm)\n",
    "print(\"\\n\")\n",
    "print(metrics.classification_report(y_test, _ann_classification_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "65aee3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "\n",
      "[[  31   70   21    1    0]\n",
      " [  25  283  221    6    1]\n",
      " [   7  140 1640   76    0]\n",
      " [   1   23  310  266   12]\n",
      " [   1    3   18  115   29]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.477     0.252     0.330       123\n",
      "           1      0.545     0.528     0.536       536\n",
      "           2      0.742     0.880     0.805      1863\n",
      "           3      0.573     0.435     0.494       612\n",
      "           4      0.690     0.175     0.279       166\n",
      "\n",
      "    accuracy                          0.682      3300\n",
      "   macro avg      0.606     0.454     0.489      3300\n",
      "weighted avg      0.666     0.682     0.660      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ann_classification = ClassificationModel(model_name=\"ANN\", parameter_dict={'early_stopping':True, 'validation_fraction': 0.1})\n",
    "_ann_classification.fit(np.array(X_train[\"Embeds\"].tolist()), y_train)\n",
    "_ann_classification_predictions = _ann_classification.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_ann_classification_cm = _ann_classification.get_confusion_matrix(y_test, list(_ann_classification_predictions))\n",
    "print(\"CONFUSION MATRIX\\n\")\n",
    "print(_ann_classification_cm)\n",
    "print(\"\\n\")\n",
    "print(metrics.classification_report(y_test, _ann_classification_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "fc97ecf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "\n",
      "[[  25   86   11    1    0]\n",
      " [  25  330  175    6    0]\n",
      " [   4  192 1552  107    8]\n",
      " [   2   28  244  306   32]\n",
      " [   0    1   13   86   66]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.446     0.203     0.279       123\n",
      "           1      0.518     0.616     0.563       536\n",
      "           2      0.778     0.833     0.805      1863\n",
      "           3      0.605     0.500     0.547       612\n",
      "           4      0.623     0.398     0.485       166\n",
      "\n",
      "    accuracy                          0.691      3300\n",
      "   macro avg      0.594     0.510     0.536      3300\n",
      "weighted avg      0.683     0.691     0.682      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ann_classification = ClassificationModel(model_name=\"ANN\", parameter_dict={'learning_rate':'invscaling', 'early_stopping':True, 'validation_fraction': 0.1, 'shuffle':True})\n",
    "_ann_classification.fit(np.array(X_train[\"Embeds\"].tolist()), y_train)\n",
    "_ann_classification_predictions = _ann_classification.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_ann_classification_cm = _ann_classification.get_confusion_matrix(y_test, list(_ann_classification_predictions))\n",
    "print(\"CONFUSION MATRIX\\n\")\n",
    "print(_ann_classification_cm)\n",
    "print(\"\\n\")\n",
    "print(metrics.classification_report(y_test, _ann_classification_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b2fd3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
