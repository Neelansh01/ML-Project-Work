{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47156fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156055</th>\n",
       "      <td>156056</td>\n",
       "      <td>8544</td>\n",
       "      <td>Hearst 's</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156056</th>\n",
       "      <td>156057</td>\n",
       "      <td>8544</td>\n",
       "      <td>forced avuncular chortles</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156057</th>\n",
       "      <td>156058</td>\n",
       "      <td>8544</td>\n",
       "      <td>avuncular chortles</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156058</th>\n",
       "      <td>156059</td>\n",
       "      <td>8544</td>\n",
       "      <td>avuncular</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156059</th>\n",
       "      <td>156060</td>\n",
       "      <td>8544</td>\n",
       "      <td>chortles</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156060 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        PhraseId  SentenceId  \\\n",
       "0              1           1   \n",
       "1              2           1   \n",
       "2              3           1   \n",
       "3              4           1   \n",
       "4              5           1   \n",
       "...          ...         ...   \n",
       "156055    156056        8544   \n",
       "156056    156057        8544   \n",
       "156057    156058        8544   \n",
       "156058    156059        8544   \n",
       "156059    156060        8544   \n",
       "\n",
       "                                                   Phrase  Sentiment  \n",
       "0       A series of escapades demonstrating the adage ...          1  \n",
       "1       A series of escapades demonstrating the adage ...          2  \n",
       "2                                                A series          2  \n",
       "3                                                       A          2  \n",
       "4                                                  series          2  \n",
       "...                                                   ...        ...  \n",
       "156055                                          Hearst 's          2  \n",
       "156056                          forced avuncular chortles          1  \n",
       "156057                                 avuncular chortles          3  \n",
       "156058                                          avuncular          2  \n",
       "156059                                           chortles          2  \n",
       "\n",
       "[156060 rows x 4 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read TSV file into DataFrame\n",
    "df = pd.read_table('Project Files/train.tsv/train.tsv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40d2e17d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>of escapades demonstrating the adage that what...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>of</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>escapades demonstrating the adage that what is...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>escapades</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>demonstrating the adage that what is good for ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "5         6           1  of escapades demonstrating the adage that what...   \n",
       "6         7           1                                                 of   \n",
       "7         8           1  escapades demonstrating the adage that what is...   \n",
       "8         9           1                                          escapades   \n",
       "9        10           1  demonstrating the adage that what is good for ...   \n",
       "\n",
       "   Sentiment  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  \n",
       "5          2  \n",
       "6          2  \n",
       "7          2  \n",
       "8          2  \n",
       "9          2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1be52d5",
   "metadata": {},
   "source": [
    "We can see that the sentences are divided into phrases which are assigned sentiments in the above data sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fe8a89",
   "metadata": {},
   "source": [
    "## To chech if all  the phrases are assigned a unique ID, making them all of them unique identifier for records in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cffb7988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _total_number_phrases(df, column_name):\n",
    "    phrases = df[column_name]\n",
    "    return phrases, len(phrases)\n",
    "\n",
    "phrases, _n_phrases = _total_number_phrases(df, \"PhraseId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de9337e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156060"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Checking the length of list of unique phrase set\n",
    "len(list(set(phrases)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afa4ceb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156060"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Checking the length of list of all phrases\n",
    "len(phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d259684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All the Phrases have UNIQUE ID.\n"
     ]
    }
   ],
   "source": [
    "def _are_unique(phrases):\n",
    "    if len(list(set(phrases)))==len(phrases):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "if _are_unique(phrases):\n",
    "    print(\"All the Phrases have UNIQUE ID.\")\n",
    "else:\n",
    "    print(\"Phrase ID is not unique.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6177fd95",
   "metadata": {},
   "source": [
    "## Analyzing all the attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6ec3b91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Sentiments\n",
    "set(df[\"Sentiment\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59183090",
   "metadata": {},
   "source": [
    "There are 5 sentiments classes in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c0bcf2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8529"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(df['SentenceId']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a223615",
   "metadata": {},
   "source": [
    "There are unique 8529 sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf658a5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156060"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(set(df['PhraseId']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed991697",
   "metadata": {},
   "source": [
    "There are 156060 unique phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c337159f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156060"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(df['Phrase']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95357cc6",
   "metadata": {},
   "source": [
    "The phrase content is unique as well and is 156060 in number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9bd9aca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PhraseId      0\n",
       "SentenceId    0\n",
       "Phrase        0\n",
       "Sentiment     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7951dd5",
   "metadata": {},
   "source": [
    "## Finding Embeddings of the Phrases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930d6fa3",
   "metadata": {},
   "source": [
    "SETTING UP CLASS FOR INDEPENDENT MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b674646c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "class PreTrained_EmbeddingModels:\n",
    "    def __init__(self, model_url=None, model_name=None, model=None):\n",
    "        self.model_url = model_url\n",
    "        self.model_name = model_name\n",
    "        self.model = model\n",
    "        self._load(model_url)\n",
    "        \n",
    "    def _load(self, model_url):\n",
    "        if self.model != None:\n",
    "            print(\"Model Switching is disabled.\")\n",
    "            return\n",
    "        self.model = SentenceTransformer(model_url)\n",
    "        \n",
    "    def _get_model(self):\n",
    "        return self.model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dd62d5",
   "metadata": {},
   "source": [
    "LOADING BERT MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2190e964",
   "metadata": {},
   "source": [
    "model_instance_bert = PreTrained_EmbeddingModels(model_url=\"sentence-transformers/all-mpnet-base-v2\", model_name=\"MPNET\")._get_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5868983",
   "metadata": {},
   "source": [
    "FINDING EMBEDDINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55c7445a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_bert = model_instance_bert.encode(df['Phrase'].tolist()[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17241144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f15acc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('mypickle_03.pickle', 'wb') as f:\n",
    "    pickle.dump([embeddings_bert], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db27804",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(phrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfa2585",
   "metadata": {},
   "source": [
    "## Training and Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab799fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Processing_DF = pd.DataFrame(df.iloc[:10000,:])\n",
    "Processing_DF['Embeds'] = list(embeddings_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94c7c115",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Processing_DF.sample(frac=1)\n",
    "Processing_DF.sample(frac=1)\n",
    "Processing_DF.sample(frac=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(Processing_DF.drop(['Sentiment'],axis=1), list(Processing_DF['Sentiment']), test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b423964",
   "metadata": {},
   "source": [
    "## Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0434699c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationModel:\n",
    "    def __init__(self, model_name=None, parameter_dict=None):\n",
    "        self.model_name = model_name\n",
    "        self.parameter_dict = parameter_dict\n",
    "        self.model = self.load_model()\n",
    "        \n",
    "    def load_model(self):            \n",
    "        if self.model_name in [\"Naive Bayes\", \"NB\"]:\n",
    "            from sklearn.naive_bayes import GaussianNB\n",
    "            return GaussianNB(**self.parameter_dict)\n",
    "\n",
    "        elif self.model_name in [\"Support Vector Machine\", \"SVC\"]:\n",
    "            from sklearn.svm import SVC\n",
    "            from sklearn.pipeline import make_pipeline\n",
    "            from sklearn.preprocessing import StandardScaler\n",
    "            return make_pipeline(StandardScaler(), SVC(**self.parameter_dict))\n",
    "\n",
    "        elif self.model_name in [\"Logistic Regression\", \"LR\"]:\n",
    "            from sklearn.linear_model import LogisticRegression\n",
    "            return LogisticRegression(**self.parameter_dict)\n",
    "\n",
    "        elif self.model_name in [\"Decision Tree\", \"DT\"]:\n",
    "            from sklearn.tree import DecisionTreeClassifier\n",
    "            return DecisionTreeClassifier(**self.parameter_dict)\n",
    "\n",
    "        elif self.model_name in [\"K Nearest Neighbour\", \"KNN\"]:\n",
    "            from sklearn.neighbors import KNeighborsClassifier\n",
    "            return KNeighborsClassifier(**self.parameter_dict)\n",
    "\n",
    "        elif self.model_name in [\"Multi Layer Perceptron\", \"ANN\"]:\n",
    "            from sklearn.neural_network import MLPClassifier\n",
    "            return MLPClassifier(**self.parameter_dict)\n",
    "\n",
    "        elif self.model_name in [\"Gradient Boosted Decision Tree\", \"GBDT\"]:\n",
    "            from sklearn.ensemble import GradientBoostingClassifier\n",
    "            return GradientBoostingClassifier(**self.parameter_dict)\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "    def fit(self, features, labels):\n",
    "        self.model = self.model.fit(features, labels)\n",
    "        \n",
    "    def predict(self, test_data):\n",
    "        return self.model.predict(test_data)\n",
    "    \n",
    "    def get_confusion_matrix(self, actual, prediction):\n",
    "        from sklearn.metrics import confusion_matrix\n",
    "        return confusion_matrix(actual,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d1b4ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1739e9",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4246829a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "\n",
      "[[  57   45   14    4    3]\n",
      " [ 114  210  156   31   25]\n",
      " [  46  193 1330  164  130]\n",
      " [  22   53  167  228  142]\n",
      " [   1    3   12   55   95]]\n",
      "\n",
      "1920\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.237     0.463     0.314       123\n",
      "           1      0.417     0.392     0.404       536\n",
      "           2      0.792     0.714     0.751      1863\n",
      "           3      0.473     0.373     0.417       612\n",
      "           4      0.241     0.572     0.339       166\n",
      "\n",
      "    accuracy                          0.582      3300\n",
      "   macro avg      0.432     0.503     0.445      3300\n",
      "weighted avg      0.624     0.582     0.596      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_naive_bayes = ClassificationModel(model_name=\"NB\", parameter_dict={})\n",
    "_naive_bayes.fit(np.array(X_train[\"Embeds\"].tolist()),y_train)\n",
    "_naive_bayes_predictions = _naive_bayes.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_naive_bayes_cm = _naive_bayes.get_confusion_matrix(y_test, _naive_bayes_predictions)\n",
    "print(\"CONFUSION MATRIX\\n\")\n",
    "print(_naive_bayes_cm)\n",
    "print(\"\\n\"+str(sum([_naive_bayes_cm[i][j] for i in range(len(_naive_bayes_cm)) for j in range(len(_naive_bayes_cm[i]))  if i==j]))+\"\\n\")\n",
    "print(metrics.classification_report(y_test, _naive_bayes_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb416b3",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e20f3d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "\n",
      "[[  12   83   24    4    0]\n",
      " [   9  254  252   21    0]\n",
      " [   4   98 1677   82    2]\n",
      " [   1   25  287  283   16]\n",
      " [   0    1   26  109   30]]\n",
      "\n",
      "2256\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.462     0.098     0.161       123\n",
      "           1      0.551     0.474     0.510       536\n",
      "           2      0.740     0.900     0.812      1863\n",
      "           3      0.567     0.462     0.509       612\n",
      "           4      0.625     0.181     0.280       166\n",
      "\n",
      "    accuracy                          0.684      3300\n",
      "   macro avg      0.589     0.423     0.455      3300\n",
      "weighted avg      0.661     0.684     0.656      3300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91945\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "_logistic_regression = ClassificationModel(model_name=\"LR\", parameter_dict={'penalty':'l2'})\n",
    "_logistic_regression.fit(np.array(X_train[\"Embeds\"].tolist()),y_train)\n",
    "_logistic_regression_predictions = _logistic_regression.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_logistic_regression_cm = _logistic_regression.get_confusion_matrix(y_test, _logistic_regression_predictions)\n",
    "print(\"CONFUSION MATRIX\\n\")\n",
    "print(_logistic_regression_cm)\n",
    "print(\"\\n\"+str(sum([_logistic_regression_cm[i][j] for i in range(len(_logistic_regression_cm)) for j in range(len(_logistic_regression_cm[i]))  if i==j]))+\"\\n\")\n",
    "print(metrics.classification_report(y_test, _logistic_regression_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f04d6e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "\n",
      "[[  69   43    4    4    3]\n",
      " [ 136  269   85   33   13]\n",
      " [  57  263 1253  253   37]\n",
      " [  17   55  116  301  123]\n",
      " [   0    3    3   39  121]]\n",
      "\n",
      "2013\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.247     0.561     0.343       123\n",
      "           1      0.425     0.502     0.460       536\n",
      "           2      0.858     0.673     0.754      1863\n",
      "           3      0.478     0.492     0.485       612\n",
      "           4      0.407     0.729     0.523       166\n",
      "\n",
      "    accuracy                          0.610      3300\n",
      "   macro avg      0.483     0.591     0.513      3300\n",
      "weighted avg      0.672     0.610     0.629      3300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91945\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "_logistic_regression = ClassificationModel(model_name=\"LR\", parameter_dict={'penalty':'l2','tol':0.00000001,'class_weight':'balanced'})\n",
    "_logistic_regression.fit(np.array(X_train[\"Embeds\"].tolist()),y_train)\n",
    "_logistic_regression_predictions = _logistic_regression.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_logistic_regression_cm = _logistic_regression.get_confusion_matrix(y_test, _logistic_regression_predictions)\n",
    "print(\"CONFUSION MATRIX\\n\")\n",
    "print(_logistic_regression_cm)\n",
    "print(\"\\n\"+str(sum([_logistic_regression_cm[i][j] for i in range(len(_logistic_regression_cm)) for j in range(len(_logistic_regression_cm[i]))  if i==j]))+\"\\n\")\n",
    "print(metrics.classification_report(y_test, _logistic_regression_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e173bce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "\n",
      "[[  12   83   25    3    0]\n",
      " [   9  254  252   21    0]\n",
      " [   4   98 1677   82    2]\n",
      " [   1   25  287  283   16]\n",
      " [   0    1   26  110   29]]\n",
      "\n",
      "2255\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.462     0.098     0.161       123\n",
      "           1      0.551     0.474     0.510       536\n",
      "           2      0.740     0.900     0.812      1863\n",
      "           3      0.567     0.462     0.509       612\n",
      "           4      0.617     0.175     0.272       166\n",
      "\n",
      "    accuracy                          0.683      3300\n",
      "   macro avg      0.587     0.422     0.453      3300\n",
      "weighted avg      0.661     0.683     0.655      3300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91945\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    }
   ],
   "source": [
    "_logistic_regression = ClassificationModel(model_name=\"LR\", parameter_dict={'penalty':'l2','tol':0.00000001,'solver':'saga'})\n",
    "_logistic_regression.fit(np.array(X_train[\"Embeds\"].tolist()),y_train)\n",
    "_logistic_regression_predictions = _logistic_regression.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_logistic_regression_cm = _logistic_regression.get_confusion_matrix(y_test, _logistic_regression_predictions)\n",
    "print(\"CONFUSION MATRIX\\n\")\n",
    "print(_logistic_regression_cm)\n",
    "print(\"\\n\"+str(sum([_logistic_regression_cm[i][j] for i in range(len(_logistic_regression_cm)) for j in range(len(_logistic_regression_cm[i]))  if i==j]))+\"\\n\")\n",
    "print(metrics.classification_report(y_test, _logistic_regression_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "10b57341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "\n",
      "[[  12   83   25    3    0]\n",
      " [   9  254  252   21    0]\n",
      " [   4   98 1677   82    2]\n",
      " [   1   25  287  283   16]\n",
      " [   0    1   26  110   29]]\n",
      "\n",
      "2255\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.462     0.098     0.161       123\n",
      "           1      0.551     0.474     0.510       536\n",
      "           2      0.740     0.900     0.812      1863\n",
      "           3      0.567     0.462     0.509       612\n",
      "           4      0.617     0.175     0.272       166\n",
      "\n",
      "    accuracy                          0.683      3300\n",
      "   macro avg      0.587     0.422     0.453      3300\n",
      "weighted avg      0.661     0.683     0.655      3300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91945\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    }
   ],
   "source": [
    "_logistic_regression = ClassificationModel(model_name=\"LR\", parameter_dict={'penalty':'l2','tol':0.00000001,'solver':'sag'})\n",
    "_logistic_regression.fit(np.array(X_train[\"Embeds\"].tolist()),y_train)\n",
    "_logistic_regression_predictions = _logistic_regression.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_logistic_regression_cm = _logistic_regression.get_confusion_matrix(y_test, _logistic_regression_predictions)\n",
    "print(\"CONFUSION MATRIX\\n\")\n",
    "print(_logistic_regression_cm)\n",
    "print(\"\\n\"+str(sum([_logistic_regression_cm[i][j] for i in range(len(_logistic_regression_cm)) for j in range(len(_logistic_regression_cm[i]))  if i==j]))+\"\\n\")\n",
    "print(metrics.classification_report(y_test, _logistic_regression_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "038bc2fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "\n",
      "[[   5   86   30    2    0]\n",
      " [   3  235  276   22    0]\n",
      " [   1   81 1711   68    2]\n",
      " [   0   29  330  248    5]\n",
      " [   0    1   35  114   16]]\n",
      "\n",
      "2215\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.556     0.041     0.076       123\n",
      "           1      0.544     0.438     0.486       536\n",
      "           2      0.718     0.918     0.806      1863\n",
      "           3      0.546     0.405     0.465       612\n",
      "           4      0.696     0.096     0.169       166\n",
      "\n",
      "    accuracy                          0.671      3300\n",
      "   macro avg      0.612     0.380     0.400      3300\n",
      "weighted avg      0.651     0.671     0.632      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_logistic_regression = ClassificationModel(model_name=\"LR\", parameter_dict={'penalty':'l1','tol':0.00000001, 'solver':'liblinear'})\n",
    "_logistic_regression.fit(np.array(X_train[\"Embeds\"].tolist()),y_train)\n",
    "_logistic_regression_predictions = _logistic_regression.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_logistic_regression_cm = _logistic_regression.get_confusion_matrix(y_test, _logistic_regression_predictions)\n",
    "print(\"CONFUSION MATRIX\\n\")\n",
    "print(_logistic_regression_cm)\n",
    "print(\"\\n\"+str(sum([_logistic_regression_cm[i][j] for i in range(len(_logistic_regression_cm)) for j in range(len(_logistic_regression_cm[i]))  if i==j]))+\"\\n\")\n",
    "print(metrics.classification_report(y_test, _logistic_regression_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d8979a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "\n",
      "[[  12   83   25    3    0]\n",
      " [   9  254  252   21    0]\n",
      " [   4   98 1677   82    2]\n",
      " [   1   25  287  283   16]\n",
      " [   0    1   26  110   29]]\n",
      "\n",
      "2255\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.462     0.098     0.161       123\n",
      "           1      0.551     0.474     0.510       536\n",
      "           2      0.740     0.900     0.812      1863\n",
      "           3      0.567     0.462     0.509       612\n",
      "           4      0.617     0.175     0.272       166\n",
      "\n",
      "    accuracy                          0.683      3300\n",
      "   macro avg      0.587     0.422     0.453      3300\n",
      "weighted avg      0.661     0.683     0.655      3300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91945\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\91945\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:195: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n"
     ]
    }
   ],
   "source": [
    "_logistic_regression = ClassificationModel(model_name=\"LR\", parameter_dict={'penalty':'l2','tol':0.00000001, 'solver':'newton-cg'})\n",
    "_logistic_regression.fit(np.array(X_train[\"Embeds\"].tolist()),y_train)\n",
    "_logistic_regression_predictions = _logistic_regression.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_logistic_regression_cm = _logistic_regression.get_confusion_matrix(y_test, _logistic_regression_predictions)\n",
    "print(\"CONFUSION MATRIX\\n\")\n",
    "print(_logistic_regression_cm)\n",
    "print(\"\\n\"+str(sum([_logistic_regression_cm[i][j] for i in range(len(_logistic_regression_cm)) for j in range(len(_logistic_regression_cm[i]))  if i==j]))+\"\\n\")\n",
    "print(metrics.classification_report(y_test, _logistic_regression_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8685a28f",
   "metadata": {},
   "source": [
    "## Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6f96fb34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "\n",
      "[[  20   84   19    0    0]\n",
      " [  13  268  246    9    0]\n",
      " [   5   92 1697   68    1]\n",
      " [   0   17  292  287   16]\n",
      " [   0    0   18  112   36]]\n",
      "\n",
      "2308\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.526     0.163     0.248       123\n",
      "           1      0.581     0.500     0.538       536\n",
      "           2      0.747     0.911     0.821      1863\n",
      "           3      0.603     0.469     0.528       612\n",
      "           4      0.679     0.217     0.329       166\n",
      "\n",
      "    accuracy                          0.699      3300\n",
      "   macro avg      0.627     0.452     0.493      3300\n",
      "weighted avg      0.682     0.699     0.674      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_svc_classification = ClassificationModel(model_name=\"SVC\", parameter_dict={})\n",
    "_svc_classification.fit(np.array(X_train[\"Embeds\"].tolist()),y_train)\n",
    "_svc_classification_predictions = _svc_classification.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_svc_classification_cm = _svc_classification.get_confusion_matrix(y_test, _svc_classification_predictions)\n",
    "print(\"CONFUSION MATRIX\\n\")\n",
    "print(_svc_classification_cm)\n",
    "print(\"\\n\"+str(sum([_svc_classification_cm[i][j] for i in range(len(_svc_classification_cm)) for j in range(len(_svc_classification_cm[i]))  if i==j]))+\"\\n\")\n",
    "print(metrics.classification_report(y_test, _svc_classification_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "27c85ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "\n",
      "[[  20   72   31    0    0]\n",
      " [  13  205  312    6    0]\n",
      " [   7   55 1733   67    1]\n",
      " [   0   13  358  225   16]\n",
      " [   0    0   40   94   32]]\n",
      "\n",
      "2215\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.500     0.163     0.245       123\n",
      "           1      0.594     0.382     0.465       536\n",
      "           2      0.700     0.930     0.799      1863\n",
      "           3      0.574     0.368     0.448       612\n",
      "           4      0.653     0.193     0.298       166\n",
      "\n",
      "    accuracy                          0.671      3300\n",
      "   macro avg      0.604     0.407     0.451      3300\n",
      "weighted avg      0.650     0.671     0.634      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_svc_classification = ClassificationModel(model_name=\"SVC\", parameter_dict={'kernel':'poly'})\n",
    "_svc_classification.fit(np.array(X_train[\"Embeds\"].tolist()),y_train)\n",
    "_svc_classification_predictions = _svc_classification.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_svc_classification_cm = _svc_classification.get_confusion_matrix(y_test, _svc_classification_predictions)\n",
    "print(\"CONFUSION MATRIX\\n\")\n",
    "print(_svc_classification_cm)\n",
    "print(\"\\n\"+str(sum([_svc_classification_cm[i][j] for i in range(len(_svc_classification_cm)) for j in range(len(_svc_classification_cm[i]))  if i==j]))+\"\\n\")\n",
    "print(metrics.classification_report(y_test, _svc_classification_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a3e4c161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "\n",
      "[[   5   90   26    2    0]\n",
      " [   6  257  258   15    0]\n",
      " [   1  112 1650  100    0]\n",
      " [   0   36  286  279   11]\n",
      " [   0    2   20  124   20]]\n",
      "\n",
      "2211\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.417     0.041     0.074       123\n",
      "           1      0.517     0.479     0.498       536\n",
      "           2      0.737     0.886     0.804      1863\n",
      "           3      0.537     0.456     0.493       612\n",
      "           4      0.645     0.120     0.203       166\n",
      "\n",
      "    accuracy                          0.670      3300\n",
      "   macro avg      0.570     0.396     0.414      3300\n",
      "weighted avg      0.647     0.670     0.639      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_svc_classification = ClassificationModel(model_name=\"SVC\", parameter_dict={'kernel':'sigmoid'})\n",
    "_svc_classification.fit(np.array(X_train[\"Embeds\"].tolist()),y_train)\n",
    "_svc_classification_predictions = _svc_classification.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_svc_classification_cm = _svc_classification.get_confusion_matrix(y_test, _svc_classification_predictions)\n",
    "print(\"CONFUSION MATRIX\\n\")\n",
    "print(_svc_classification_cm)\n",
    "print(\"\\n\"+str(sum([_svc_classification_cm[i][j] for i in range(len(_svc_classification_cm)) for j in range(len(_svc_classification_cm[i]))  if i==j]))+\"\\n\")\n",
    "print(metrics.classification_report(y_test, _svc_classification_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a1374ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "\n",
      "[[  19   73   31    0    0]\n",
      " [  12  203  315    6    0]\n",
      " [   7   55 1733   67    1]\n",
      " [   0   13  360  224   15]\n",
      " [   0    0   40   95   31]]\n",
      "\n",
      "2210\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.500     0.154     0.236       123\n",
      "           1      0.590     0.379     0.461       536\n",
      "           2      0.699     0.930     0.798      1863\n",
      "           3      0.571     0.366     0.446       612\n",
      "           4      0.660     0.187     0.291       166\n",
      "\n",
      "    accuracy                          0.670      3300\n",
      "   macro avg      0.604     0.403     0.447      3300\n",
      "weighted avg      0.648     0.670     0.632      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_svc_classification = ClassificationModel(model_name=\"SVC\", parameter_dict={'kernel':'poly','gamma':'auto'})\n",
    "_svc_classification.fit(np.array(X_train[\"Embeds\"].tolist()),y_train)\n",
    "_svc_classification_predictions = _svc_classification.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_svc_classification_cm = _svc_classification.get_confusion_matrix(y_test, _svc_classification_predictions)\n",
    "print(\"CONFUSION MATRIX\\n\")\n",
    "print(_svc_classification_cm)\n",
    "print(\"\\n\"+str(sum([_svc_classification_cm[i][j] for i in range(len(_svc_classification_cm)) for j in range(len(_svc_classification_cm[i]))  if i==j]))+\"\\n\")\n",
    "print(metrics.classification_report(y_test, _svc_classification_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8808bcdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "\n",
      "[[  20   84   19    0    0]\n",
      " [  13  268  246    9    0]\n",
      " [   5   92 1697   68    1]\n",
      " [   0   17  292  287   16]\n",
      " [   0    0   18  112   36]]\n",
      "\n",
      "2308\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.526     0.163     0.248       123\n",
      "           1      0.581     0.500     0.538       536\n",
      "           2      0.747     0.911     0.821      1863\n",
      "           3      0.603     0.469     0.528       612\n",
      "           4      0.679     0.217     0.329       166\n",
      "\n",
      "    accuracy                          0.699      3300\n",
      "   macro avg      0.627     0.452     0.493      3300\n",
      "weighted avg      0.682     0.699     0.674      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_svc_classification = ClassificationModel(model_name=\"SVC\", parameter_dict={'gamma':'auto'})\n",
    "_svc_classification.fit(np.array(X_train[\"Embeds\"].tolist()),y_train)\n",
    "_svc_classification_predictions = _svc_classification.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_svc_classification_cm = _svc_classification.get_confusion_matrix(y_test, _svc_classification_predictions)\n",
    "print(\"CONFUSION MATRIX\\n\")\n",
    "print(_svc_classification_cm)\n",
    "print(\"\\n\"+str(sum([_svc_classification_cm[i][j] for i in range(len(_svc_classification_cm)) for j in range(len(_svc_classification_cm[i]))  if i==j]))+\"\\n\")\n",
    "print(metrics.classification_report(y_test, _svc_classification_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc80529",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5c48a1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "\n",
      "[[  47   61   14    1    0]\n",
      " [  91  241  181   22    1]\n",
      " [  35  203 1449  167    9]\n",
      " [  11   58  276  228   39]\n",
      " [   3    6   42   64   51]]\n",
      "\n",
      "2016\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.251     0.382     0.303       123\n",
      "           1      0.424     0.450     0.436       536\n",
      "           2      0.739     0.778     0.758      1863\n",
      "           3      0.473     0.373     0.417       612\n",
      "           4      0.510     0.307     0.383       166\n",
      "\n",
      "    accuracy                          0.611      3300\n",
      "   macro avg      0.479     0.458     0.459      3300\n",
      "weighted avg      0.608     0.611     0.606      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_knn_classification = ClassificationModel(model_name=\"KNN\", parameter_dict={'n_neighbors':3})\n",
    "_knn_classification.fit(np.array(X_train[\"Embeds\"].tolist()), y_train)\n",
    "_knn_classification_predictions = _knn_classification.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_knn_classification_cm = _knn_classification.get_confusion_matrix(y_test, list(_knn_classification_predictions))\n",
    "print(\"CONFUSION MATRIX\\n\")\n",
    "print(_knn_classification_cm)\n",
    "print(\"\\n\"+str(sum([_knn_classification_cm[i][j] for i in range(len(_knn_classification_cm)) for j in range(len(_knn_classification_cm[i]))  if i==j]))+\"\\n\")\n",
    "print(metrics.classification_report(y_test, _knn_classification_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c6111b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "\n",
      "[[  35   63   24    1    0]\n",
      " [  39  236  235   26    0]\n",
      " [  13  128 1567  144   11]\n",
      " [   1   28  272  277   34]\n",
      " [   1    0   23   88   54]]\n",
      "\n",
      "2169\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.393     0.285     0.330       123\n",
      "           1      0.519     0.440     0.476       536\n",
      "           2      0.739     0.841     0.787      1863\n",
      "           3      0.517     0.453     0.483       612\n",
      "           4      0.545     0.325     0.408       166\n",
      "\n",
      "    accuracy                          0.657      3300\n",
      "   macro avg      0.543     0.469     0.497      3300\n",
      "weighted avg      0.639     0.657     0.644      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_knn_classification = ClassificationModel(model_name=\"KNN\", parameter_dict={'n_neighbors':7,'weights':'distance'})\n",
    "_knn_classification.fit(np.array(X_train[\"Embeds\"].tolist()), y_train)\n",
    "_knn_classification_predictions = _knn_classification.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_knn_classification_cm = _knn_classification.get_confusion_matrix(y_test, list(_knn_classification_predictions))\n",
    "print(\"CONFUSION MATRIX\\n\")\n",
    "print(_knn_classification_cm)\n",
    "print(\"\\n\"+str(sum([_knn_classification_cm[i][j] for i in range(len(_knn_classification_cm)) for j in range(len(_knn_classification_cm[i]))  if i==j]))+\"\\n\")\n",
    "print(metrics.classification_report(y_test, _knn_classification_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3e80a7cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "\n",
      "[[  35   63   24    1    0]\n",
      " [  39  236  235   26    0]\n",
      " [  13  128 1567  144   11]\n",
      " [   1   28  272  277   34]\n",
      " [   1    0   23   88   54]]\n",
      "\n",
      "2169\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.393     0.285     0.330       123\n",
      "           1      0.519     0.440     0.476       536\n",
      "           2      0.739     0.841     0.787      1863\n",
      "           3      0.517     0.453     0.483       612\n",
      "           4      0.545     0.325     0.408       166\n",
      "\n",
      "    accuracy                          0.657      3300\n",
      "   macro avg      0.543     0.469     0.497      3300\n",
      "weighted avg      0.639     0.657     0.644      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_knn_classification = ClassificationModel(model_name=\"KNN\", parameter_dict={'n_neighbors':7,'weights':'distance','algorithm':'kd_tree'})\n",
    "_knn_classification.fit(np.array(X_train[\"Embeds\"].tolist()), y_train)\n",
    "_knn_classification_predictions = _knn_classification.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_knn_classification_cm = _knn_classification.get_confusion_matrix(y_test, list(_knn_classification_predictions))\n",
    "print(\"CONFUSION MATRIX\\n\")\n",
    "print(_knn_classification_cm)\n",
    "print(\"\\n\"+str(sum([_knn_classification_cm[i][j] for i in range(len(_knn_classification_cm)) for j in range(len(_knn_classification_cm[i]))  if i==j]))+\"\\n\")\n",
    "print(metrics.classification_report(y_test, _knn_classification_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bf406c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "\n",
      "[[  34   65   23    1    0]\n",
      " [  40  230  241   25    0]\n",
      " [  13  123 1574  141   12]\n",
      " [   2   32  272  270   36]\n",
      " [   1    0   25   87   53]]\n",
      "\n",
      "2161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.378     0.276     0.319       123\n",
      "           1      0.511     0.429     0.467       536\n",
      "           2      0.737     0.845     0.787      1863\n",
      "           3      0.515     0.441     0.475       612\n",
      "           4      0.525     0.319     0.397       166\n",
      "\n",
      "    accuracy                          0.655      3300\n",
      "   macro avg      0.533     0.462     0.489      3300\n",
      "weighted avg      0.635     0.655     0.640      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_knn_classification = ClassificationModel(model_name=\"KNN\", parameter_dict={'p':1, 'n_neighbors':7,'weights':'distance','algorithm':'kd_tree'})\n",
    "_knn_classification.fit(np.array(X_train[\"Embeds\"].tolist()), y_train)\n",
    "_knn_classification_predictions = _knn_classification.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_knn_classification_cm = _knn_classification.get_confusion_matrix(y_test, list(_knn_classification_predictions))\n",
    "print(\"CONFUSION MATRIX\\n\")\n",
    "print(_knn_classification_cm)\n",
    "print(\"\\n\"+str(sum([_knn_classification_cm[i][j] for i in range(len(_knn_classification_cm)) for j in range(len(_knn_classification_cm[i]))  if i==j]))+\"\\n\")\n",
    "print(metrics.classification_report(y_test, _knn_classification_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0eaed9e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "\n",
      "[[  35   63   24    1    0]\n",
      " [  39  236  235   26    0]\n",
      " [  13  128 1567  144   11]\n",
      " [   1   28  272  277   34]\n",
      " [   1    0   23   88   54]]\n",
      "\n",
      "2169\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.393     0.285     0.330       123\n",
      "           1      0.519     0.440     0.476       536\n",
      "           2      0.739     0.841     0.787      1863\n",
      "           3      0.517     0.453     0.483       612\n",
      "           4      0.545     0.325     0.408       166\n",
      "\n",
      "    accuracy                          0.657      3300\n",
      "   macro avg      0.543     0.469     0.497      3300\n",
      "weighted avg      0.639     0.657     0.644      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_knn_classification = ClassificationModel(model_name=\"KNN\", parameter_dict={'n_neighbors':7,'weights':'distance','algorithm':'ball_tree'})\n",
    "_knn_classification.fit(np.array(X_train[\"Embeds\"].tolist()), y_train)\n",
    "_knn_classification_predictions = _knn_classification.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_knn_classification_cm = _knn_classification.get_confusion_matrix(y_test, list(_knn_classification_predictions))\n",
    "print(\"CONFUSION MATRIX\\n\")\n",
    "print(_knn_classification_cm)\n",
    "print(\"\\n\"+str(sum([_knn_classification_cm[i][j] for i in range(len(_knn_classification_cm)) for j in range(len(_knn_classification_cm[i]))  if i==j]))+\"\\n\")\n",
    "print(metrics.classification_report(y_test, _knn_classification_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "35ba97f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "\n",
      "[[  34   65   23    1    0]\n",
      " [  40  230  241   25    0]\n",
      " [  13  123 1574  141   12]\n",
      " [   2   32  272  270   36]\n",
      " [   1    0   25   87   53]]\n",
      "\n",
      "2161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.378     0.276     0.319       123\n",
      "           1      0.511     0.429     0.467       536\n",
      "           2      0.737     0.845     0.787      1863\n",
      "           3      0.515     0.441     0.475       612\n",
      "           4      0.525     0.319     0.397       166\n",
      "\n",
      "    accuracy                          0.655      3300\n",
      "   macro avg      0.533     0.462     0.489      3300\n",
      "weighted avg      0.635     0.655     0.640      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_knn_classification = ClassificationModel(model_name=\"KNN\", parameter_dict={'p':1, 'n_neighbors':7,'weights':'distance','algorithm':'ball_tree'})\n",
    "_knn_classification.fit(np.array(X_train[\"Embeds\"].tolist()), y_train)\n",
    "_knn_classification_predictions = _knn_classification.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_knn_classification_cm = _knn_classification.get_confusion_matrix(y_test, list(_knn_classification_predictions))\n",
    "print(\"CONFUSION MATRIX\\n\")\n",
    "print(_knn_classification_cm)\n",
    "print(\"\\n\"+str(sum([_knn_classification_cm[i][j] for i in range(len(_knn_classification_cm)) for j in range(len(_knn_classification_cm[i]))  if i==j]))+\"\\n\")\n",
    "print(metrics.classification_report(y_test, _knn_classification_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ef64058f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "\n",
      "[[  29   68   25    1    0]\n",
      " [  40  224  247   25    0]\n",
      " [  10  107 1621  117    8]\n",
      " [   0   24  276  282   30]\n",
      " [   0    0   24   86   56]]\n",
      "\n",
      "2212\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.367     0.236     0.287       123\n",
      "           1      0.530     0.418     0.467       536\n",
      "           2      0.739     0.870     0.799      1863\n",
      "           3      0.552     0.461     0.502       612\n",
      "           4      0.596     0.337     0.431       166\n",
      "\n",
      "    accuracy                          0.670      3300\n",
      "   macro avg      0.557     0.464     0.497      3300\n",
      "weighted avg      0.649     0.670     0.653      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_knn_classification = ClassificationModel(model_name=\"KNN\", parameter_dict={'n_neighbors':10,'weights':'distance','p':1})\n",
    "_knn_classification.fit(np.array(X_train[\"Embeds\"].tolist()), y_train)\n",
    "_knn_classification_predictions = _knn_classification.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_knn_classification_cm = _knn_classification.get_confusion_matrix(y_test, list(_knn_classification_predictions))\n",
    "print(\"CONFUSION MATRIX\\n\")\n",
    "print(_knn_classification_cm)\n",
    "print(\"\\n\"+str(sum([_knn_classification_cm[i][j] for i in range(len(_knn_classification_cm)) for j in range(len(_knn_classification_cm[i]))  if i==j]))+\"\\n\")\n",
    "print(metrics.classification_report(y_test, _knn_classification_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a1057d",
   "metadata": {},
   "source": [
    "## Gradient Boosted Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "763bcd3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "\n",
      "[[  16   69   37    1    0]\n",
      " [   9  208  300   19    0]\n",
      " [   2   83 1707   64    7]\n",
      " [   1   22  347  222   20]\n",
      " [   0    3   45   89   29]]\n",
      "\n",
      "2182\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.571     0.130     0.212       123\n",
      "           1      0.540     0.388     0.452       536\n",
      "           2      0.701     0.916     0.794      1863\n",
      "           3      0.562     0.363     0.441       612\n",
      "           4      0.518     0.175     0.261       166\n",
      "\n",
      "    accuracy                          0.661      3300\n",
      "   macro avg      0.578     0.394     0.432      3300\n",
      "weighted avg      0.635     0.661     0.625      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_gbdt_classification = ClassificationModel(model_name=\"GBDT\", parameter_dict={})\n",
    "_gbdt_classification.fit(np.array(X_train[\"Embeds\"].tolist()), y_train)\n",
    "_gbdt_classification_predictions = _gbdt_classification.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_gbdt_classification_cm = _gbdt_classification.get_confusion_matrix(y_test, list(_gbdt_classification_predictions))\n",
    "print(\"CONFUSION MATRIX\\n\")\n",
    "print(_gbdt_classification_cm)\n",
    "print(\"\\n\"+str(sum([_gbdt_classification_cm[i][j] for i in range(len(_gbdt_classification_cm)) for j in range(len(_gbdt_classification_cm[i]))  if i==j]))+\"\\n\")\n",
    "print(metrics.classification_report(y_test, _gbdt_classification_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba65ab4c",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6c4a915e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "\n",
      "[[  17   42   46   14    4]\n",
      " [  46  182  234   65    9]\n",
      " [  63  202 1216  313   69]\n",
      " [  20   62  276  209   45]\n",
      " [   5   15   57   57   32]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.113     0.138     0.124       123\n",
      "           1      0.362     0.340     0.350       536\n",
      "           2      0.665     0.653     0.659      1863\n",
      "           3      0.318     0.342     0.329       612\n",
      "           4      0.201     0.193     0.197       166\n",
      "\n",
      "    accuracy                          0.502      3300\n",
      "   macro avg      0.332     0.333     0.332      3300\n",
      "weighted avg      0.507     0.502     0.504      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_dt_classification = ClassificationModel(model_name=\"DT\", parameter_dict={})\n",
    "_dt_classification.fit(np.array(X_train[\"Embeds\"].tolist()), y_train)\n",
    "_dt_classification_predictions = _dt_classification.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "print(\"CONFUSION MATRIX\\n\")\n",
    "_dt_classification_cm = _dt_classification.get_confusion_matrix(y_test, list(_dt_classification_predictions))\n",
    "print(_dt_classification_cm)\n",
    "print(\"\\n\")\n",
    "print(metrics.classification_report(y_test, _dt_classification_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ea68e2a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "\n",
      "[[  20   39   44   14    6]\n",
      " [  50  161  255   59   11]\n",
      " [  37  236 1239  299   52]\n",
      " [  17   75  276  196   48]\n",
      " [   4    8   49   69   36]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.156     0.163     0.159       123\n",
      "           1      0.310     0.300     0.305       536\n",
      "           2      0.665     0.665     0.665      1863\n",
      "           3      0.308     0.320     0.314       612\n",
      "           4      0.235     0.217     0.226       166\n",
      "\n",
      "    accuracy                          0.501      3300\n",
      "   macro avg      0.335     0.333     0.334      3300\n",
      "weighted avg      0.501     0.501     0.501      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_dt_classification = ClassificationModel(model_name=\"DT\", parameter_dict={'criterion':'entropy'})\n",
    "_dt_classification.fit(np.array(X_train[\"Embeds\"].tolist()), y_train)\n",
    "_dt_classification_predictions = _dt_classification.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "print(\"CONFUSION MATRIX\\n\")\n",
    "_dt_classification_cm = _dt_classification.get_confusion_matrix(y_test, list(_dt_classification_predictions))\n",
    "print(_dt_classification_cm)\n",
    "print(\"\\n\")\n",
    "print(metrics.classification_report(y_test, _dt_classification_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ca7d39c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "\n",
      "[[   0   32   82    9    0]\n",
      " [   0   77  415   42    2]\n",
      " [   0   71 1651  132    9]\n",
      " [   0   25  453  126    8]\n",
      " [   0    9  110   39    8]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000       123\n",
      "           1      0.360     0.144     0.205       536\n",
      "           2      0.609     0.886     0.722      1863\n",
      "           3      0.362     0.206     0.263       612\n",
      "           4      0.296     0.048     0.083       166\n",
      "\n",
      "    accuracy                          0.564      3300\n",
      "   macro avg      0.325     0.257     0.255      3300\n",
      "weighted avg      0.484     0.564     0.494      3300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91945\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\91945\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\91945\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "_dt_classification = ClassificationModel(model_name=\"DT\", parameter_dict={'max_depth':5})\n",
    "_dt_classification.fit(np.array(X_train[\"Embeds\"].tolist()), y_train)\n",
    "_dt_classification_predictions = _dt_classification.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "print(\"CONFUSION MATRIX\\n\")\n",
    "_dt_classification_cm = _dt_classification.get_confusion_matrix(y_test, list(_dt_classification_predictions))\n",
    "print(_dt_classification_cm)\n",
    "print(\"\\n\")\n",
    "print(metrics.classification_report(y_test, _dt_classification_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0de53f9",
   "metadata": {},
   "source": [
    "## Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b037c04b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "\n",
      "[[  39   60   20    2    2]\n",
      " [  47  277  191   19    2]\n",
      " [  12  168 1493  182    8]\n",
      " [   2   20  243  298   49]\n",
      " [   0    1   14   96   55]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.390     0.317     0.350       123\n",
      "           1      0.527     0.517     0.522       536\n",
      "           2      0.761     0.801     0.781      1863\n",
      "           3      0.499     0.487     0.493       612\n",
      "           4      0.474     0.331     0.390       166\n",
      "\n",
      "    accuracy                          0.655      3300\n",
      "   macro avg      0.530     0.491     0.507      3300\n",
      "weighted avg      0.646     0.655     0.650      3300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91945\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "_ann_classification = ClassificationModel(model_name=\"ANN\", parameter_dict={})\n",
    "_ann_classification.fit(np.array(X_train[\"Embeds\"].tolist()), y_train)\n",
    "_ann_classification_predictions = _ann_classification.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_ann_classification_cm = _ann_classification.get_confusion_matrix(y_test, list(_ann_classification_predictions))\n",
    "print(\"CONFUSION MATRIX\\n\")\n",
    "print(_ann_classification_cm)\n",
    "print(\"\\n\")\n",
    "print(metrics.classification_report(y_test, _ann_classification_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1d6ff50e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "\n",
      "[[  40   62   18    2    1]\n",
      " [  68  267  181   18    2]\n",
      " [  27  160 1523  138   15]\n",
      " [   4   35  241  267   65]\n",
      " [   0    1   16   86   63]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.288     0.325     0.305       123\n",
      "           1      0.509     0.498     0.503       536\n",
      "           2      0.770     0.817     0.793      1863\n",
      "           3      0.523     0.436     0.476       612\n",
      "           4      0.432     0.380     0.404       166\n",
      "\n",
      "    accuracy                          0.655      3300\n",
      "   macro avg      0.504     0.491     0.496      3300\n",
      "weighted avg      0.646     0.655     0.649      3300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91945\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "_ann_classification = ClassificationModel(model_name=\"ANN\", parameter_dict={'activation':'tanh'})\n",
    "_ann_classification.fit(np.array(X_train[\"Embeds\"].tolist()), y_train)\n",
    "_ann_classification_predictions = _ann_classification.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_ann_classification_cm = _ann_classification.get_confusion_matrix(y_test, list(_ann_classification_predictions))\n",
    "print(\"CONFUSION MATRIX\\n\")\n",
    "print(_ann_classification_cm)\n",
    "print(\"\\n\")\n",
    "print(metrics.classification_report(y_test, _ann_classification_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ca2e5cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "\n",
      "[[  29   73   18    3    0]\n",
      " [  24  296  197   19    0]\n",
      " [   6  154 1584  115    4]\n",
      " [   1   29  247  294   41]\n",
      " [   0    2   10   86   68]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.483     0.236     0.317       123\n",
      "           1      0.534     0.552     0.543       536\n",
      "           2      0.770     0.850     0.808      1863\n",
      "           3      0.569     0.480     0.521       612\n",
      "           4      0.602     0.410     0.487       166\n",
      "\n",
      "    accuracy                          0.688      3300\n",
      "   macro avg      0.592     0.506     0.535      3300\n",
      "weighted avg      0.675     0.688     0.677      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ann_classification = ClassificationModel(model_name=\"ANN\", parameter_dict={'early_stopping':True})\n",
    "_ann_classification.fit(np.array(X_train[\"Embeds\"].tolist()), y_train)\n",
    "_ann_classification_predictions = _ann_classification.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_ann_classification_cm = _ann_classification.get_confusion_matrix(y_test, list(_ann_classification_predictions))\n",
    "print(\"CONFUSION MATRIX\\n\")\n",
    "print(_ann_classification_cm)\n",
    "print(\"\\n\")\n",
    "print(metrics.classification_report(y_test, _ann_classification_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bfad2b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "\n",
      "[[  18   83   19    3    0]\n",
      " [  11  299  207   19    0]\n",
      " [   2  134 1601  124    2]\n",
      " [   2   23  245  317   25]\n",
      " [   0    1   10  109   46]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.545     0.146     0.231       123\n",
      "           1      0.554     0.558     0.556       536\n",
      "           2      0.769     0.859     0.812      1863\n",
      "           3      0.554     0.518     0.535       612\n",
      "           4      0.630     0.277     0.385       166\n",
      "\n",
      "    accuracy                          0.691      3300\n",
      "   macro avg      0.610     0.472     0.504      3300\n",
      "weighted avg      0.679     0.691     0.676      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ann_classification = ClassificationModel(model_name=\"ANN\", parameter_dict={'early_stopping':True, 'validation_fraction': 0.1})\n",
    "_ann_classification.fit(np.array(X_train[\"Embeds\"].tolist()), y_train)\n",
    "_ann_classification_predictions = _ann_classification.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_ann_classification_cm = _ann_classification.get_confusion_matrix(y_test, list(_ann_classification_predictions))\n",
    "print(\"CONFUSION MATRIX\\n\")\n",
    "print(_ann_classification_cm)\n",
    "print(\"\\n\")\n",
    "print(metrics.classification_report(y_test, _ann_classification_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1b01eca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "\n",
      "[[   0   97   23    3    0]\n",
      " [   0  273  237   26    0]\n",
      " [   0  121 1635  107    0]\n",
      " [   0   31  267  310    4]\n",
      " [   0    2   19  136    9]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000       123\n",
      "           1      0.521     0.509     0.515       536\n",
      "           2      0.750     0.878     0.809      1863\n",
      "           3      0.533     0.507     0.519       612\n",
      "           4      0.692     0.054     0.101       166\n",
      "\n",
      "    accuracy                          0.675      3300\n",
      "   macro avg      0.499     0.390     0.389      3300\n",
      "weighted avg      0.641     0.675     0.642      3300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91945\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\91945\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\91945\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "_ann_classification = ClassificationModel(model_name=\"ANN\", parameter_dict={'learning_rate':'invscaling', 'early_stopping':True, 'validation_fraction': 0.1, 'shuffle':True})\n",
    "_ann_classification.fit(np.array(X_train[\"Embeds\"].tolist()), y_train)\n",
    "_ann_classification_predictions = _ann_classification.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_ann_classification_cm = _ann_classification.get_confusion_matrix(y_test, list(_ann_classification_predictions))\n",
    "print(\"CONFUSION MATRIX\\n\")\n",
    "print(_ann_classification_cm)\n",
    "print(\"\\n\")\n",
    "print(metrics.classification_report(y_test, _ann_classification_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498446ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
