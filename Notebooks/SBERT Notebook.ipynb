{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47156fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156055</th>\n",
       "      <td>156056</td>\n",
       "      <td>8544</td>\n",
       "      <td>Hearst 's</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156056</th>\n",
       "      <td>156057</td>\n",
       "      <td>8544</td>\n",
       "      <td>forced avuncular chortles</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156057</th>\n",
       "      <td>156058</td>\n",
       "      <td>8544</td>\n",
       "      <td>avuncular chortles</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156058</th>\n",
       "      <td>156059</td>\n",
       "      <td>8544</td>\n",
       "      <td>avuncular</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156059</th>\n",
       "      <td>156060</td>\n",
       "      <td>8544</td>\n",
       "      <td>chortles</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156060 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        PhraseId  SentenceId  \\\n",
       "0              1           1   \n",
       "1              2           1   \n",
       "2              3           1   \n",
       "3              4           1   \n",
       "4              5           1   \n",
       "...          ...         ...   \n",
       "156055    156056        8544   \n",
       "156056    156057        8544   \n",
       "156057    156058        8544   \n",
       "156058    156059        8544   \n",
       "156059    156060        8544   \n",
       "\n",
       "                                                   Phrase  Sentiment  \n",
       "0       A series of escapades demonstrating the adage ...          1  \n",
       "1       A series of escapades demonstrating the adage ...          2  \n",
       "2                                                A series          2  \n",
       "3                                                       A          2  \n",
       "4                                                  series          2  \n",
       "...                                                   ...        ...  \n",
       "156055                                          Hearst 's          2  \n",
       "156056                          forced avuncular chortles          1  \n",
       "156057                                 avuncular chortles          3  \n",
       "156058                                          avuncular          2  \n",
       "156059                                           chortles          2  \n",
       "\n",
       "[156060 rows x 4 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read TSV file into DataFrame\n",
    "df = pd.read_table('Project Files/train.tsv/train.tsv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40d2e17d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>of escapades demonstrating the adage that what...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>of</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>escapades demonstrating the adage that what is...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>escapades</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>demonstrating the adage that what is good for ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "5         6           1  of escapades demonstrating the adage that what...   \n",
       "6         7           1                                                 of   \n",
       "7         8           1  escapades demonstrating the adage that what is...   \n",
       "8         9           1                                          escapades   \n",
       "9        10           1  demonstrating the adage that what is good for ...   \n",
       "\n",
       "   Sentiment  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  \n",
       "5          2  \n",
       "6          2  \n",
       "7          2  \n",
       "8          2  \n",
       "9          2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1be52d5",
   "metadata": {},
   "source": [
    "We can see that the sentences are divided into phrases which are assigned sentiments in the above data sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fe8a89",
   "metadata": {},
   "source": [
    "## To chech if all  the phrases are assigned a unique ID, making them all of them unique identifier for records in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cffb7988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _total_number_phrases(df, column_name):\n",
    "    phrases = df[column_name]\n",
    "    return phrases, len(phrases)\n",
    "\n",
    "phrases, _n_phrases = _total_number_phrases(df, \"PhraseId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de9337e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156060"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Checking the length of list of unique phrase set\n",
    "len(list(set(phrases)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afa4ceb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156060"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Checking the length of list of all phrases\n",
    "len(phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d259684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All the Phrases have UNIQUE ID.\n"
     ]
    }
   ],
   "source": [
    "def _are_unique(phrases):\n",
    "    if len(list(set(phrases)))==len(phrases):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "if _are_unique(phrases):\n",
    "    print(\"All the Phrases have UNIQUE ID.\")\n",
    "else:\n",
    "    print(\"Phrase ID is not unique.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6177fd95",
   "metadata": {},
   "source": [
    "## Analyzing all the attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6ec3b91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Sentiments\n",
    "set(df[\"Sentiment\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59183090",
   "metadata": {},
   "source": [
    "There are 5 sentiments classes in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c0bcf2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8529"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(df['SentenceId']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a223615",
   "metadata": {},
   "source": [
    "There are unique 8529 sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf658a5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156060"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(set(df['PhraseId']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed991697",
   "metadata": {},
   "source": [
    "There are 156060 unique phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c337159f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156060"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(df['Phrase']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95357cc6",
   "metadata": {},
   "source": [
    "The phrase content is unique as well and is 156060 in number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9bd9aca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PhraseId      0\n",
       "SentenceId    0\n",
       "Phrase        0\n",
       "Sentiment     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7951dd5",
   "metadata": {},
   "source": [
    "## Finding Embeddings of the Phrases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930d6fa3",
   "metadata": {},
   "source": [
    "SETTING UP CLASS FOR INDEPENDENT MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b674646c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "class PreTrained_EmbeddingModels:\n",
    "    def __init__(self, model_url=None, model_name=None, model=None):\n",
    "        self.model_url = model_url\n",
    "        self.model_name = model_name\n",
    "        self.model = model\n",
    "        self._load(model_url)\n",
    "        \n",
    "    def _load(self, model_url):\n",
    "        if self.model != None:\n",
    "            print(\"Model Switching is disabled.\")\n",
    "            return\n",
    "        self.model = SentenceTransformer(model_url)\n",
    "        \n",
    "    def _get_model(self):\n",
    "        return self.model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dd62d5",
   "metadata": {},
   "source": [
    "LOADING BERT MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25c617bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b397689e82d432eae46a992d63e01cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9bd33cb0fa241bbbdd3274c011e55c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cf357cbe1254b81a01f0f7b084aa53d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "992bcd1999e24dfc8626f416540f11fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f8ae1400a58430c86fa2ca681b12ead",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94e74b8c9b3143cda64daa760ef7578e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/39.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3af39f9921f54e91a49a476f9069b8bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6bea082ac034664898ffb25f0d330dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "961452fb48954c9696f997ba0fb76669",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9a410ced8a74655b6883b4e9e4f7686",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd2de5a2d0ef4c5fa8d17376663cbf21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "191301f5c04847dbbe1f19bd39300e70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/13.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "620b30db7cde4aec9579e55050f9b70a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1114d05820a4ab289c91454c6e07bcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_instance_bert = PreTrained_EmbeddingModels(model_url=\"all-MiniLM-L6-v2\", model_name=\"Sentence BERT\")._get_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5868983",
   "metadata": {},
   "source": [
    "FINDING EMBEDDINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55c7445a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_bert = model_instance_bert.encode(df['Phrase'].tolist()[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f15acc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('mypickle_01.pickle', 'wb') as f:\n",
    "    pickle.dump([embeddings_bert], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1446142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a9b48c49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings_bert[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c8746f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 384)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_bert.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0728993b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Processing_DF = pd.DataFrame(df.iloc[:10000,:])\n",
    "Processing_DF['Embeds'] = list(embeddings_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4d356b88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Embeds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.058720715, -0.032839425, 0.047727715, 0.03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[-0.01865507, -0.01602184, 0.048112143, 0.0666...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "      <td>[-0.081645176, 0.062079225, 0.004442434, 0.077...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>[-0.036432922, 0.034703396, -0.045959894, 0.03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "      <td>[-0.06352139, 0.042595528, -0.0017584751, 0.05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9996</td>\n",
       "      <td>420</td>\n",
       "      <td>plays like some corny television production fr...</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.05058179, -0.024217928, 0.0065322598, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9997</td>\n",
       "      <td>420</td>\n",
       "      <td>plays like some corny television</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.010927222, -0.10147872, 0.05232218, -0.0810...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9998</td>\n",
       "      <td>420</td>\n",
       "      <td>like some corny television</td>\n",
       "      <td>2</td>\n",
       "      <td>[-0.021114677, -0.09299212, 0.044081654, -0.04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9999</td>\n",
       "      <td>420</td>\n",
       "      <td>some corny television</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.03643913, -0.06907892, 0.050544772, -0.075...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>420</td>\n",
       "      <td>corny television</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.040166933, -0.06549238, 0.027031194, -0.08...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PhraseId  SentenceId                                             Phrase  \\\n",
       "0            1           1  A series of escapades demonstrating the adage ...   \n",
       "1            2           1  A series of escapades demonstrating the adage ...   \n",
       "2            3           1                                           A series   \n",
       "3            4           1                                                  A   \n",
       "4            5           1                                             series   \n",
       "...        ...         ...                                                ...   \n",
       "9995      9996         420  plays like some corny television production fr...   \n",
       "9996      9997         420                   plays like some corny television   \n",
       "9997      9998         420                         like some corny television   \n",
       "9998      9999         420                              some corny television   \n",
       "9999     10000         420                                   corny television   \n",
       "\n",
       "      Sentiment                                             Embeds  \n",
       "0             1  [-0.058720715, -0.032839425, 0.047727715, 0.03...  \n",
       "1             2  [-0.01865507, -0.01602184, 0.048112143, 0.0666...  \n",
       "2             2  [-0.081645176, 0.062079225, 0.004442434, 0.077...  \n",
       "3             2  [-0.036432922, 0.034703396, -0.045959894, 0.03...  \n",
       "4             2  [-0.06352139, 0.042595528, -0.0017584751, 0.05...  \n",
       "...         ...                                                ...  \n",
       "9995          1  [-0.05058179, -0.024217928, 0.0065322598, -0.0...  \n",
       "9996          1  [0.010927222, -0.10147872, 0.05232218, -0.0810...  \n",
       "9997          2  [-0.021114677, -0.09299212, 0.044081654, -0.04...  \n",
       "9998          1  [-0.03643913, -0.06907892, 0.050544772, -0.075...  \n",
       "9999          1  [-0.040166933, -0.06549238, 0.027031194, -0.08...  \n",
       "\n",
       "[10000 rows x 5 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Processing_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bca8e0",
   "metadata": {},
   "source": [
    "## Training and Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9ca1446c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Processing_DF.sample(frac=1)\n",
    "Processing_DF.sample(frac=1)\n",
    "Processing_DF.sample(frac=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(Processing_DF.drop(['Sentiment'],axis=1), list(Processing_DF['Sentiment']), test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e1cdb837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Embeds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8371</th>\n",
       "      <td>8372</td>\n",
       "      <td>348</td>\n",
       "      <td>saw this movie</td>\n",
       "      <td>[-0.055958994, 0.00279459, -0.07206712, 0.0252...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5027</th>\n",
       "      <td>5028</td>\n",
       "      <td>196</td>\n",
       "      <td>about life itself</td>\n",
       "      <td>[-0.050040357, 0.014964542, -0.026103517, 0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9234</th>\n",
       "      <td>9235</td>\n",
       "      <td>386</td>\n",
       "      <td>Bear</td>\n",
       "      <td>[-0.038280882, 0.05772985, 0.05183284, 0.11231...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3944</th>\n",
       "      <td>3945</td>\n",
       "      <td>149</td>\n",
       "      <td>a silly -LRB- but not sophomoric -RRB- romp th...</td>\n",
       "      <td>[-0.0048351, 0.0071490733, -0.06909708, -0.016...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6862</th>\n",
       "      <td>6863</td>\n",
       "      <td>275</td>\n",
       "      <td>critique</td>\n",
       "      <td>[-0.06255015, 0.14269522, -0.037193395, 0.0477...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5734</th>\n",
       "      <td>5735</td>\n",
       "      <td>227</td>\n",
       "      <td>less interesting</td>\n",
       "      <td>[0.039559014, 0.05566624, 0.062052976, 0.06134...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5191</th>\n",
       "      <td>5192</td>\n",
       "      <td>206</td>\n",
       "      <td>the well-wrought story</td>\n",
       "      <td>[-0.023460204, 0.11553944, 0.08540614, 0.10312...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>5391</td>\n",
       "      <td>215</td>\n",
       "      <td>to make than it is to sit through</td>\n",
       "      <td>[0.018826177, 0.033386596, 0.02532654, 0.07621...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>861</td>\n",
       "      <td>32</td>\n",
       "      <td>by a self-indulgent script</td>\n",
       "      <td>[-0.006140305, 0.030622993, 0.00408741, 0.0061...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7270</th>\n",
       "      <td>7271</td>\n",
       "      <td>297</td>\n",
       "      <td>maintaining the appearance of clinical objecti...</td>\n",
       "      <td>[0.09644151, 0.029239021, -0.017993486, 0.0186...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6700 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PhraseId  SentenceId                                             Phrase  \\\n",
       "8371      8372         348                                     saw this movie   \n",
       "5027      5028         196                                  about life itself   \n",
       "9234      9235         386                                               Bear   \n",
       "3944      3945         149  a silly -LRB- but not sophomoric -RRB- romp th...   \n",
       "6862      6863         275                                           critique   \n",
       "...        ...         ...                                                ...   \n",
       "5734      5735         227                                   less interesting   \n",
       "5191      5192         206                             the well-wrought story   \n",
       "5390      5391         215                  to make than it is to sit through   \n",
       "860        861          32                         by a self-indulgent script   \n",
       "7270      7271         297  maintaining the appearance of clinical objecti...   \n",
       "\n",
       "                                                 Embeds  \n",
       "8371  [-0.055958994, 0.00279459, -0.07206712, 0.0252...  \n",
       "5027  [-0.050040357, 0.014964542, -0.026103517, 0.02...  \n",
       "9234  [-0.038280882, 0.05772985, 0.05183284, 0.11231...  \n",
       "3944  [-0.0048351, 0.0071490733, -0.06909708, -0.016...  \n",
       "6862  [-0.06255015, 0.14269522, -0.037193395, 0.0477...  \n",
       "...                                                 ...  \n",
       "5734  [0.039559014, 0.05566624, 0.062052976, 0.06134...  \n",
       "5191  [-0.023460204, 0.11553944, 0.08540614, 0.10312...  \n",
       "5390  [0.018826177, 0.033386596, 0.02532654, 0.07621...  \n",
       "860   [-0.006140305, 0.030622993, 0.00408741, 0.0061...  \n",
       "7270  [0.09644151, 0.029239021, -0.017993486, 0.0186...  \n",
       "\n",
       "[6700 rows x 4 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "231e064f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " ...]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44503cf",
   "metadata": {},
   "source": [
    "## Class Definition for Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "0434699c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationModel:\n",
    "    def __init__(self, model_name=None, parameter_dict=None):\n",
    "        self.model_name = model_name\n",
    "        self.parameter_dict = parameter_dict\n",
    "        self.model = self.load_model()\n",
    "        \n",
    "    def load_model(self):            \n",
    "        if self.model_name in [\"Naive Bayes\", \"NB\"]:\n",
    "            from sklearn.naive_bayes import GaussianNB\n",
    "            return GaussianNB(**self.parameter_dict)\n",
    "\n",
    "        elif self.model_name in [\"Support Vector Machine\", \"SVC\"]:\n",
    "            from sklearn.svm import SVC\n",
    "            from sklearn.pipeline import make_pipeline\n",
    "            from sklearn.preprocessing import StandardScaler\n",
    "            return make_pipeline(StandardScaler(), SVC(**self.parameter_dict))\n",
    "\n",
    "        elif self.model_name in [\"Logistic Regression\", \"LR\"]:\n",
    "            from sklearn.linear_model import LogisticRegression\n",
    "            return LogisticRegression(**self.parameter_dict)\n",
    "\n",
    "        elif self.model_name in [\"Decision Tree\", \"DT\"]:\n",
    "            from sklearn.tree import DecisionTreeClassifier\n",
    "            return DecisionTreeClassifier(**self.parameter_dict)\n",
    "\n",
    "        elif self.model_name in [\"K Nearest Neighbour\", \"KNN\"]:\n",
    "            from sklearn.neighbors import KNeighborsClassifier\n",
    "            return KNeighborsClassifier(**self.parameter_dict)\n",
    "\n",
    "        elif self.model_name in [\"Multi Layer Perceptron\", \"ANN\"]:\n",
    "            from sklearn.neural_network import MLPClassifier\n",
    "            return MLPClassifier(**self.parameter_dict)\n",
    "\n",
    "        elif self.model_name in [\"Gradient Boosted Decision Tree\", \"GBDT\"]:\n",
    "            from sklearn.ensemble import GradientBoostingClassifier\n",
    "            return GradientBoostingClassifier(**self.parameter_dict)\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "    def fit(self, features, labels):\n",
    "        self.model = self.model.fit(features, labels)\n",
    "        \n",
    "    def predict(self, test_data):\n",
    "        return self.model.predict(test_data)\n",
    "    \n",
    "    def get_confusion_matrix(self, actual, prediction):\n",
    "        from sklearn.metrics import confusion_matrix\n",
    "        return confusion_matrix(actual,prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a47803a",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "82b2b4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91945\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass priors=None as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    }
   ],
   "source": [
    "_naive_bayes = ClassificationModel(model_name=\"NB\", parameter_dict=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "fe388603",
   "metadata": {},
   "outputs": [],
   "source": [
    "_naive_bayes.fit(np.array(X_train[\"Embeds\"].tolist()),y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "39b41982",
   "metadata": {},
   "outputs": [],
   "source": [
    "_naive_bayes_predictions = _naive_bayes.predict(np.array(X_test[\"Embeds\"].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "c0be3255",
   "metadata": {},
   "outputs": [],
   "source": [
    "_naive_bayes_cm = _naive_bayes.get_confusion_matrix(y_test, _naive_bayes_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "86f581bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "\n",
      "[[  52   44   12    4   11]\n",
      " [  77  208  154   44   53]\n",
      " [  61  201 1279  204  118]\n",
      " [  26   62  172  221  131]\n",
      " [   2    5   21   51   87]]\n"
     ]
    }
   ],
   "source": [
    "print(\"CONFUSION MATRIX\\n\")\n",
    "print(_naive_bayes_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "3311f1cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1847"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([_naive_bayes_cm[i][j] for i in range(len(_naive_bayes_cm)) for j in range(len(_naive_bayes_cm[i]))  if i==j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "0c2a3f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.239     0.423     0.305       123\n",
      "           1      0.400     0.388     0.394       536\n",
      "           2      0.781     0.687     0.731      1863\n",
      "           3      0.422     0.361     0.389       612\n",
      "           4      0.217     0.524     0.307       166\n",
      "\n",
      "    accuracy                          0.560      3300\n",
      "   macro avg      0.412     0.477     0.425      3300\n",
      "weighted avg      0.604     0.560     0.575      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test, _naive_bayes_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "1fc45c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  52   44   12    4   11]\n",
      " [  77  208  154   44   53]\n",
      " [  61  201 1279  204  118]\n",
      " [  26   62  172  221  131]\n",
      " [   2    5   21   51   87]]\n",
      "1847\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.239     0.423     0.305       123\n",
      "           1      0.400     0.388     0.394       536\n",
      "           2      0.781     0.687     0.731      1863\n",
      "           3      0.422     0.361     0.389       612\n",
      "           4      0.217     0.524     0.307       166\n",
      "\n",
      "    accuracy                          0.560      3300\n",
      "   macro avg      0.412     0.477     0.425      3300\n",
      "weighted avg      0.604     0.560     0.575      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_naive_bayes = ClassificationModel(model_name=\"NB\", parameter_dict={})\n",
    "_naive_bayes.fit(np.array(X_train[\"Embeds\"].tolist()),y_train)\n",
    "_naive_bayes_predictions = _naive_bayes.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_naive_bayes_cm = _naive_bayes.get_confusion_matrix(y_test, _naive_bayes_predictions)\n",
    "print(_naive_bayes_cm)\n",
    "print(sum([_naive_bayes_cm[i][j] for i in range(len(_naive_bayes_cm)) for j in range(len(_naive_bayes_cm[i]))  if i==j]))\n",
    "print(metrics.classification_report(y_test, _naive_bayes_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72860ea",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "eaed165c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_logistic_regression = ClassificationModel(model_name=\"LR\", parameter_dict={'penalty':'l2'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "cbd134e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91945\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "_logistic_regression.fit(np.array(X_train[\"Embeds\"].tolist()),y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "a9f43bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "_logistic_regression_predictions = _logistic_regression.predict(np.array(X_test[\"Embeds\"].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "94345b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "\n",
      "[[  12   74   35    2    0]\n",
      " [   8  201  292   29    6]\n",
      " [   3   93 1670   96    1]\n",
      " [   2   37  304  258   11]\n",
      " [   0    5   34  102   25]]\n"
     ]
    }
   ],
   "source": [
    "_logistic_regression_cm = _logistic_regression.get_confusion_matrix(y_test, _logistic_regression_predictions)\n",
    "print(\"CONFUSION MATRIX\\n\")\n",
    "print(_logistic_regression_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "be6bec1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.239     0.423     0.305       123\n",
      "           1      0.400     0.388     0.394       536\n",
      "           2      0.781     0.687     0.731      1863\n",
      "           3      0.422     0.361     0.389       612\n",
      "           4      0.217     0.524     0.307       166\n",
      "\n",
      "    accuracy                          0.560      3300\n",
      "   macro avg      0.412     0.477     0.425      3300\n",
      "weighted avg      0.604     0.560     0.575      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, _naive_bayes_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "c152c24c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2166"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([_logistic_regression_cm[i][j] for i in range(len(_logistic_regression_cm)) for j in range(len(_logistic_regression_cm[i]))  if i==j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "572d870c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "\n",
      "[[  12   74   35    2    0]\n",
      " [   8  201  292   29    6]\n",
      " [   3   93 1670   96    1]\n",
      " [   2   37  304  258   11]\n",
      " [   0    5   34  102   25]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.480     0.098     0.162       123\n",
      "           1      0.490     0.375     0.425       536\n",
      "           2      0.715     0.896     0.796      1863\n",
      "           3      0.530     0.422     0.470       612\n",
      "           4      0.581     0.151     0.239       166\n",
      "\n",
      "    accuracy                          0.656      3300\n",
      "   macro avg      0.559     0.388     0.418      3300\n",
      "weighted avg      0.629     0.656     0.623      3300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91945\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "_logistic_regression = ClassificationModel(model_name=\"LR\", parameter_dict={'penalty':'l2','tol':0.00000001})\n",
    "_logistic_regression.fit(np.array(X_train[\"Embeds\"].tolist()),y_train)\n",
    "_logistic_regression_predictions = _logistic_regression.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_logistic_regression_cm = _logistic_regression.get_confusion_matrix(y_test, _logistic_regression_predictions)\n",
    "print(\"CONFUSION MATRIX\\n\")\n",
    "print(_logistic_regression_cm)\n",
    "#print(sum([_logistic_regression_cm[i][j] for i in range(len(_logistic_regression_cm)) for j in range(len(_logistic_regression_cm[i]))  if i==j]))\n",
    "print(metrics.classification_report(y_test, _logistic_regression_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "a8e528c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "\n",
      "[[  57   57    4    3    2]\n",
      " [ 124  247   95   47   23]\n",
      " [  66  285 1197  253   62]\n",
      " [  26   59  122  253  152]\n",
      " [   4    2    4   40  116]]\n",
      "1870\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.206     0.463     0.285       123\n",
      "           1      0.380     0.461     0.417       536\n",
      "           2      0.842     0.643     0.729      1863\n",
      "           3      0.424     0.413     0.419       612\n",
      "           4      0.327     0.699     0.445       166\n",
      "\n",
      "    accuracy                          0.567      3300\n",
      "   macro avg      0.436     0.536     0.459      3300\n",
      "weighted avg      0.640     0.567     0.590      3300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91945\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "_logistic_regression = ClassificationModel(model_name=\"LR\", parameter_dict={'penalty':'l2','tol':0.00000001,'class_weight':'balanced'})\n",
    "_logistic_regression.fit(np.array(X_train[\"Embeds\"].tolist()),y_train)\n",
    "_logistic_regression_predictions = _logistic_regression.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_logistic_regression_cm = _logistic_regression.get_confusion_matrix(y_test, _logistic_regression_predictions)\n",
    "print(\"CONFUSION MATRIX\\n\")\n",
    "print(_logistic_regression_cm)\n",
    "print(sum([_logistic_regression_cm[i][j] for i in range(len(_logistic_regression_cm)) for j in range(len(_logistic_regression_cm[i]))  if i==j]))\n",
    "print(metrics.classification_report(y_test, _logistic_regression_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "cbc668a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "\n",
      "[[  12   74   35    2    0]\n",
      " [   8  200  292   30    6]\n",
      " [   3   93 1670   96    1]\n",
      " [   2   37  304  258   11]\n",
      " [   0    5   36  100   25]]\n",
      "2165\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.480     0.098     0.162       123\n",
      "           1      0.489     0.373     0.423       536\n",
      "           2      0.715     0.896     0.795      1863\n",
      "           3      0.531     0.422     0.470       612\n",
      "           4      0.581     0.151     0.239       166\n",
      "\n",
      "    accuracy                          0.656      3300\n",
      "   macro avg      0.559     0.388     0.418      3300\n",
      "weighted avg      0.628     0.656     0.623      3300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91945\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    }
   ],
   "source": [
    "_logistic_regression = ClassificationModel(model_name=\"LR\", parameter_dict={'penalty':'l2','tol':0.00000001, 'solver':'saga'})\n",
    "_logistic_regression.fit(np.array(X_train[\"Embeds\"].tolist()),y_train)\n",
    "_logistic_regression_predictions = _logistic_regression.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_logistic_regression_cm = _logistic_regression.get_confusion_matrix(y_test, _logistic_regression_predictions)\n",
    "print(\"CONFUSION MATRIX\\n\")\n",
    "print(_logistic_regression_cm)\n",
    "print(sum([_logistic_regression_cm[i][j] for i in range(len(_logistic_regression_cm)) for j in range(len(_logistic_regression_cm[i]))  if i==j]))\n",
    "print(metrics.classification_report(y_test, _logistic_regression_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "67fb1ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  12   74   35    2    0]\n",
      " [   8  200  292   30    6]\n",
      " [   3   93 1670   96    1]\n",
      " [   2   37  304  258   11]\n",
      " [   0    5   36  100   25]]\n",
      "2165\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.480     0.098     0.162       123\n",
      "           1      0.489     0.373     0.423       536\n",
      "           2      0.715     0.896     0.795      1863\n",
      "           3      0.531     0.422     0.470       612\n",
      "           4      0.581     0.151     0.239       166\n",
      "\n",
      "    accuracy                          0.656      3300\n",
      "   macro avg      0.559     0.388     0.418      3300\n",
      "weighted avg      0.628     0.656     0.623      3300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91945\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    }
   ],
   "source": [
    "_logistic_regression = ClassificationModel(model_name=\"LR\", parameter_dict={'penalty':'l2','tol':0.00000001, 'solver':'sag'})\n",
    "_logistic_regression.fit(np.array(X_train[\"Embeds\"].tolist()),y_train)\n",
    "_logistic_regression_predictions = _logistic_regression.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_logistic_regression_cm = _logistic_regression.get_confusion_matrix(y_test, _logistic_regression_predictions)\n",
    "print(_logistic_regression_cm)\n",
    "print(sum([_logistic_regression_cm[i][j] for i in range(len(_logistic_regression_cm)) for j in range(len(_logistic_regression_cm[i]))  if i==j]))\n",
    "print(metrics.classification_report(y_test, _logistic_regression_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "8a4c8e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  10   68   41    3    1]\n",
      " [   6  195  297   35    3]\n",
      " [   3   81 1691   88    0]\n",
      " [   0   40  317  247    8]\n",
      " [   1    5   38  102   20]]\n",
      "2163\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.500     0.081     0.140       123\n",
      "           1      0.501     0.364     0.422       536\n",
      "           2      0.709     0.908     0.796      1863\n",
      "           3      0.520     0.404     0.454       612\n",
      "           4      0.625     0.120     0.202       166\n",
      "\n",
      "    accuracy                          0.655      3300\n",
      "   macro avg      0.571     0.375     0.403      3300\n",
      "weighted avg      0.628     0.655     0.618      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_logistic_regression = ClassificationModel(model_name=\"LR\", parameter_dict={'penalty':'l1','tol':0.00000001, 'solver':'liblinear'})\n",
    "_logistic_regression.fit(np.array(X_train[\"Embeds\"].tolist()),y_train)\n",
    "_logistic_regression_predictions = _logistic_regression.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_logistic_regression_cm = _logistic_regression.get_confusion_matrix(y_test, _logistic_regression_predictions)\n",
    "print(_logistic_regression_cm)\n",
    "print(sum([_logistic_regression_cm[i][j] for i in range(len(_logistic_regression_cm)) for j in range(len(_logistic_regression_cm[i]))  if i==j]))\n",
    "print(metrics.classification_report(y_test, _logistic_regression_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "52a6408d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  12   74   35    2    0]\n",
      " [   8  200  292   30    6]\n",
      " [   3   93 1670   96    1]\n",
      " [   2   37  304  258   11]\n",
      " [   0    5   36  100   25]]\n",
      "2165\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.480     0.098     0.162       123\n",
      "           1      0.489     0.373     0.423       536\n",
      "           2      0.715     0.896     0.795      1863\n",
      "           3      0.531     0.422     0.470       612\n",
      "           4      0.581     0.151     0.239       166\n",
      "\n",
      "    accuracy                          0.656      3300\n",
      "   macro avg      0.559     0.388     0.418      3300\n",
      "weighted avg      0.628     0.656     0.623      3300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91945\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\91945\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:195: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n"
     ]
    }
   ],
   "source": [
    "_logistic_regression = ClassificationModel(model_name=\"LR\", parameter_dict={'penalty':'l2','tol':0.00000001, 'solver':'newton-cg'})\n",
    "_logistic_regression.fit(np.array(X_train[\"Embeds\"].tolist()),y_train)\n",
    "_logistic_regression_predictions = _logistic_regression.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_logistic_regression_cm = _logistic_regression.get_confusion_matrix(y_test, _logistic_regression_predictions)\n",
    "print(_logistic_regression_cm)\n",
    "print(sum([_logistic_regression_cm[i][j] for i in range(len(_logistic_regression_cm)) for j in range(len(_logistic_regression_cm[i]))  if i==j]))\n",
    "print(metrics.classification_report(y_test, _logistic_regression_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c517ae9",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "aafbd955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "\n",
      "[[  17   82   23    1    0]\n",
      " [  14  243  264   15    0]\n",
      " [   5   85 1693   80    0]\n",
      " [   0   23  299  279   11]\n",
      " [   0    1   18  113   34]]\n"
     ]
    }
   ],
   "source": [
    "_svc_classification = ClassificationModel(model_name=\"SVC\", parameter_dict={})\n",
    "_svc_classification.fit(np.array(X_train[\"Embeds\"].tolist()),y_train)\n",
    "_svc_classification_predictions = _svc_classification.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_svc_classification_cm = _svc_classification.get_confusion_matrix(y_test, _svc_classification_predictions)\n",
    "print(\"CONFUSION MATRIX\\n\")\n",
    "print(_svc_classification_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "237ffb21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.472     0.138     0.214       123\n",
      "           1      0.560     0.453     0.501       536\n",
      "           2      0.737     0.909     0.814      1863\n",
      "           3      0.572     0.456     0.507       612\n",
      "           4      0.756     0.205     0.322       166\n",
      "\n",
      "    accuracy                          0.687      3300\n",
      "   macro avg      0.619     0.432     0.472      3300\n",
      "weighted avg      0.669     0.687     0.659      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, _svc_classification_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "bd144fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2266"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([_svc_classification_cm[i][j] for i in range(len(_svc_classification_cm)) for j in range(len(_svc_classification_cm[i]))  if i==j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "e4c8e4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  18   69   36    0    0]\n",
      " [  13  211  302   10    0]\n",
      " [   6   77 1691   88    1]\n",
      " [   0   13  344  237   18]\n",
      " [   0    0   43   95   28]]\n",
      "2185\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.486     0.146     0.225       123\n",
      "           1      0.570     0.394     0.466       536\n",
      "           2      0.700     0.908     0.790      1863\n",
      "           3      0.551     0.387     0.455       612\n",
      "           4      0.596     0.169     0.263       166\n",
      "\n",
      "    accuracy                          0.662      3300\n",
      "   macro avg      0.581     0.401     0.440      3300\n",
      "weighted avg      0.638     0.662     0.628      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_svc_classification = ClassificationModel(model_name=\"SVC\", parameter_dict={'kernel':'poly'})\n",
    "_svc_classification.fit(np.array(X_train[\"Embeds\"].tolist()),y_train)\n",
    "_svc_classification_predictions = _svc_classification.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_svc_classification_cm = _svc_classification.get_confusion_matrix(y_test, _svc_classification_predictions)\n",
    "print(_svc_classification_cm)\n",
    "#print(sum([_svc_classification_cm[i][j] for i in range(len(_svc_classification_cm)) for j in range(len(_svc_classification_cm[i]))  if i==j]))\n",
    "print(metrics.classification_report(y_test, _svc_classification_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "9dfc7f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   8   71   39    5    0]\n",
      " [   7  201  284   42    2]\n",
      " [   2  126 1613  119    3]\n",
      " [   3   50  316  241    2]\n",
      " [   0   12   33  112    9]]\n",
      "2072\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.400     0.065     0.112       123\n",
      "           1      0.437     0.375     0.404       536\n",
      "           2      0.706     0.866     0.778      1863\n",
      "           3      0.464     0.394     0.426       612\n",
      "           4      0.562     0.054     0.099       166\n",
      "\n",
      "    accuracy                          0.628      3300\n",
      "   macro avg      0.514     0.351     0.364      3300\n",
      "weighted avg      0.599     0.628     0.593      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_svc_classification = ClassificationModel(model_name=\"SVC\", parameter_dict={'kernel':'sigmoid'})\n",
    "_svc_classification.fit(np.array(X_train[\"Embeds\"].tolist()),y_train)\n",
    "_svc_classification_predictions = _svc_classification.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_svc_classification_cm = _svc_classification.get_confusion_matrix(y_test, _svc_classification_predictions)\n",
    "print(_svc_classification_cm)\n",
    "print(sum([_svc_classification_cm[i][j] for i in range(len(_svc_classification_cm)) for j in range(len(_svc_classification_cm[i]))  if i==j]))\n",
    "print(metrics.classification_report(y_test, _svc_classification_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "dd915eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  18   69   36    0    0]\n",
      " [  13  209  304   10    0]\n",
      " [   6   74 1698   84    1]\n",
      " [   0   13  346  235   18]\n",
      " [   0    0   43   95   28]]\n",
      "2188\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.486     0.146     0.225       123\n",
      "           1      0.573     0.390     0.464       536\n",
      "           2      0.700     0.911     0.792      1863\n",
      "           3      0.554     0.384     0.454       612\n",
      "           4      0.596     0.169     0.263       166\n",
      "\n",
      "    accuracy                          0.663      3300\n",
      "   macro avg      0.582     0.400     0.439      3300\n",
      "weighted avg      0.639     0.663     0.628      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_svc_classification = ClassificationModel(model_name=\"SVC\", parameter_dict={'kernel':'poly','gamma':'auto'})\n",
    "_svc_classification.fit(np.array(X_train[\"Embeds\"].tolist()),y_train)\n",
    "_svc_classification_predictions = _svc_classification.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_svc_classification_cm = _svc_classification.get_confusion_matrix(y_test, _svc_classification_predictions)\n",
    "print(_svc_classification_cm)\n",
    "print(sum([_svc_classification_cm[i][j] for i in range(len(_svc_classification_cm)) for j in range(len(_svc_classification_cm[i]))  if i==j]))\n",
    "print(metrics.classification_report(y_test, _svc_classification_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "4efc0288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  17   82   23    1    0]\n",
      " [  14  243  264   15    0]\n",
      " [   5   86 1691   81    0]\n",
      " [   0   23  299  279   11]\n",
      " [   0    1   18  113   34]]\n",
      "2264\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.472     0.138     0.214       123\n",
      "           1      0.559     0.453     0.501       536\n",
      "           2      0.737     0.908     0.813      1863\n",
      "           3      0.571     0.456     0.507       612\n",
      "           4      0.756     0.205     0.322       166\n",
      "\n",
      "    accuracy                          0.686      3300\n",
      "   macro avg      0.619     0.432     0.471      3300\n",
      "weighted avg      0.668     0.686     0.659      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_svc_classification = ClassificationModel(model_name=\"SVC\", parameter_dict={'gamma':'auto'})\n",
    "_svc_classification.fit(np.array(X_train[\"Embeds\"].tolist()),y_train)\n",
    "_svc_classification_predictions = _svc_classification.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_svc_classification_cm = _svc_classification.get_confusion_matrix(y_test, _svc_classification_predictions)\n",
    "print(_svc_classification_cm)\n",
    "print(sum([_svc_classification_cm[i][j] for i in range(len(_svc_classification_cm)) for j in range(len(_svc_classification_cm[i]))  if i==j]))\n",
    "print(metrics.classification_report(y_test, _svc_classification_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7ecab8",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "7f9ed7df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  44,   59,   19,    1,    0],\n",
       "       [  83,  242,  191,   18,    2],\n",
       "       [  39,  188, 1453,  173,   10],\n",
       "       [  16,   39,  290,  230,   37],\n",
       "       [   1,    5,   36,   74,   50]], dtype=int64)"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_knn_classification = ClassificationModel(model_name=\"KNN\", parameter_dict={'n_neighbors':3})\n",
    "_knn_classification.fit(np.array(X_train[\"Embeds\"].tolist()), y_train)\n",
    "_knn_classification_predictions = _knn_classification.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_knn_classification_cm = _knn_classification.get_confusion_matrix(y_test, list(_knn_classification_predictions))\n",
    "_knn_classification_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "598a18ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2019"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([_knn_classification_cm[i][j] for i in range(len(_knn_classification_cm)) for j in range(len(_knn_classification_cm[i]))  if i==j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "b87f8e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.240     0.358     0.288       123\n",
      "           1      0.454     0.451     0.453       536\n",
      "           2      0.731     0.780     0.754      1863\n",
      "           3      0.464     0.376     0.415       612\n",
      "           4      0.505     0.301     0.377       166\n",
      "\n",
      "    accuracy                          0.612      3300\n",
      "   macro avg      0.479     0.453     0.457      3300\n",
      "weighted avg      0.607     0.612     0.606      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, _knn_classification_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "6dbd9cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "\n",
      "[[  39   62   20    1    1]\n",
      " [  42  238  230   26    0]\n",
      " [  16  128 1549  159   11]\n",
      " [   1   21  283  266   41]\n",
      " [   0    1   29   84   52]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.398     0.317     0.353       123\n",
      "           1      0.529     0.444     0.483       536\n",
      "           2      0.734     0.831     0.780      1863\n",
      "           3      0.496     0.435     0.463       612\n",
      "           4      0.495     0.313     0.384       166\n",
      "\n",
      "    accuracy                          0.650      3300\n",
      "   macro avg      0.530     0.468     0.492      3300\n",
      "weighted avg      0.632     0.650     0.637      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_knn_classification = ClassificationModel(model_name=\"KNN\", parameter_dict={'n_neighbors':7,'weights':'distance'})\n",
    "_knn_classification.fit(np.array(X_train[\"Embeds\"].tolist()), y_train)\n",
    "_knn_classification_predictions = _knn_classification.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_knn_classification_cm = _knn_classification.get_confusion_matrix(y_test, list(_knn_classification_predictions))\n",
    "print(\"CONFUSION MATRIX\\n\")\n",
    "print(_knn_classification_cm)\n",
    "#print(sum([_knn_classification_cm[i][j] for i in range(len(_knn_classification_cm)) for j in range(len(_knn_classification_cm[i]))  if i==j]))\n",
    "print(metrics.classification_report(y_test, _knn_classification_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "91381233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  39   62   20    1    1]\n",
      " [  42  238  230   26    0]\n",
      " [  16  128 1549  159   11]\n",
      " [   1   21  283  266   41]\n",
      " [   0    1   29   84   52]]\n",
      "2144\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.398     0.317     0.353       123\n",
      "           1      0.529     0.444     0.483       536\n",
      "           2      0.734     0.831     0.780      1863\n",
      "           3      0.496     0.435     0.463       612\n",
      "           4      0.495     0.313     0.384       166\n",
      "\n",
      "    accuracy                          0.650      3300\n",
      "   macro avg      0.530     0.468     0.492      3300\n",
      "weighted avg      0.632     0.650     0.637      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_knn_classification = ClassificationModel(model_name=\"KNN\", parameter_dict={'n_neighbors':7,'weights':'distance','algorithm':'kd_tree'})\n",
    "_knn_classification.fit(np.array(X_train[\"Embeds\"].tolist()), y_train)\n",
    "_knn_classification_predictions = _knn_classification.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_knn_classification_cm = _knn_classification.get_confusion_matrix(y_test, list(_knn_classification_predictions))\n",
    "print(_knn_classification_cm)\n",
    "print(sum([_knn_classification_cm[i][j] for i in range(len(_knn_classification_cm)) for j in range(len(_knn_classification_cm[i]))  if i==j]))\n",
    "print(metrics.classification_report(y_test, _knn_classification_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "c13f9845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  39   61   20    2    1]\n",
      " [  41  241  225   28    1]\n",
      " [  18  131 1545  158   11]\n",
      " [   0   22  289  261   40]\n",
      " [   0    0   27   88   51]]\n",
      "2137\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.398     0.317     0.353       123\n",
      "           1      0.530     0.450     0.486       536\n",
      "           2      0.734     0.829     0.779      1863\n",
      "           3      0.486     0.426     0.454       612\n",
      "           4      0.490     0.307     0.378       166\n",
      "\n",
      "    accuracy                          0.648      3300\n",
      "   macro avg      0.528     0.466     0.490      3300\n",
      "weighted avg      0.630     0.648     0.635      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_knn_classification = ClassificationModel(model_name=\"KNN\", parameter_dict={'p':1, 'n_neighbors':7,'weights':'distance','algorithm':'kd_tree'})\n",
    "_knn_classification.fit(np.array(X_train[\"Embeds\"].tolist()), y_train)\n",
    "_knn_classification_predictions = _knn_classification.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_knn_classification_cm = _knn_classification.get_confusion_matrix(y_test, list(_knn_classification_predictions))\n",
    "print(_knn_classification_cm)\n",
    "print(sum([_knn_classification_cm[i][j] for i in range(len(_knn_classification_cm)) for j in range(len(_knn_classification_cm[i]))  if i==j]))\n",
    "print(metrics.classification_report(y_test, _knn_classification_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "88005db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  39   62   20    1    1]\n",
      " [  42  238  230   26    0]\n",
      " [  16  128 1549  159   11]\n",
      " [   1   21  283  266   41]\n",
      " [   0    1   29   84   52]]\n",
      "2144\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.398     0.317     0.353       123\n",
      "           1      0.529     0.444     0.483       536\n",
      "           2      0.734     0.831     0.780      1863\n",
      "           3      0.496     0.435     0.463       612\n",
      "           4      0.495     0.313     0.384       166\n",
      "\n",
      "    accuracy                          0.650      3300\n",
      "   macro avg      0.530     0.468     0.492      3300\n",
      "weighted avg      0.632     0.650     0.637      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_knn_classification = ClassificationModel(model_name=\"KNN\", parameter_dict={'n_neighbors':7,'weights':'distance','algorithm':'ball_tree'})\n",
    "_knn_classification.fit(np.array(X_train[\"Embeds\"].tolist()), y_train)\n",
    "_knn_classification_predictions = _knn_classification.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_knn_classification_cm = _knn_classification.get_confusion_matrix(y_test, list(_knn_classification_predictions))\n",
    "print(_knn_classification_cm)\n",
    "print(sum([_knn_classification_cm[i][j] for i in range(len(_knn_classification_cm)) for j in range(len(_knn_classification_cm[i]))  if i==j]))\n",
    "print(metrics.classification_report(y_test, _knn_classification_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "0fcb920f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  39   61   20    2    1]\n",
      " [  41  241  225   28    1]\n",
      " [  18  131 1545  158   11]\n",
      " [   0   22  289  261   40]\n",
      " [   0    0   27   88   51]]\n",
      "2137\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.398     0.317     0.353       123\n",
      "           1      0.530     0.450     0.486       536\n",
      "           2      0.734     0.829     0.779      1863\n",
      "           3      0.486     0.426     0.454       612\n",
      "           4      0.490     0.307     0.378       166\n",
      "\n",
      "    accuracy                          0.648      3300\n",
      "   macro avg      0.528     0.466     0.490      3300\n",
      "weighted avg      0.630     0.648     0.635      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_knn_classification = ClassificationModel(model_name=\"KNN\", parameter_dict={'p':1, 'n_neighbors':7,'weights':'distance','algorithm':'ball_tree'})\n",
    "_knn_classification.fit(np.array(X_train[\"Embeds\"].tolist()), y_train)\n",
    "_knn_classification_predictions = _knn_classification.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_knn_classification_cm = _knn_classification.get_confusion_matrix(y_test, list(_knn_classification_predictions))\n",
    "print(_knn_classification_cm)\n",
    "print(sum([_knn_classification_cm[i][j] for i in range(len(_knn_classification_cm)) for j in range(len(_knn_classification_cm[i]))  if i==j]))\n",
    "print(metrics.classification_report(y_test, _knn_classification_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "6765fd19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  32   61   26    3    1]\n",
      " [  33  229  246   28    0]\n",
      " [  16  100 1611  129    7]\n",
      " [   1   20  311  243   37]\n",
      " [   0    0   32   88   46]]\n",
      "2161\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.390     0.260     0.312       123\n",
      "           1      0.559     0.427     0.484       536\n",
      "           2      0.724     0.865     0.788      1863\n",
      "           3      0.495     0.397     0.441       612\n",
      "           4      0.505     0.277     0.358       166\n",
      "\n",
      "    accuracy                          0.655      3300\n",
      "   macro avg      0.535     0.445     0.477      3300\n",
      "weighted avg      0.631     0.655     0.635      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_knn_classification = ClassificationModel(model_name=\"KNN\", parameter_dict={'n_neighbors':10,'weights':'distance','p':1})\n",
    "_knn_classification.fit(np.array(X_train[\"Embeds\"].tolist()), y_train)\n",
    "_knn_classification_predictions = _knn_classification.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_knn_classification_cm = _knn_classification.get_confusion_matrix(y_test, list(_knn_classification_predictions))\n",
    "print(_knn_classification_cm)\n",
    "print(sum([_knn_classification_cm[i][j] for i in range(len(_knn_classification_cm)) for j in range(len(_knn_classification_cm[i]))  if i==j]))\n",
    "print(metrics.classification_report(y_test, _knn_classification_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5ce483",
   "metadata": {},
   "source": [
    "## Gradient Boosted Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "0e09873a",
   "metadata": {},
   "outputs": [],
   "source": [
    "_gbdt_classification = ClassificationModel(model_name=\"GBDT\", parameter_dict={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "4ef77bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "_gbdt_classification.fit(np.array(X_train[\"Embeds\"].tolist()), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "3971b647",
   "metadata": {},
   "outputs": [],
   "source": [
    "_gbdt_classification_predictions = _gbdt_classification.predict(np.array(X_test[\"Embeds\"].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "9181c4eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  14,   59,   47,    3,    0],\n",
       "       [  15,  171,  326,   21,    3],\n",
       "       [   5,   66, 1715,   76,    1],\n",
       "       [   2,   30,  364,  196,   20],\n",
       "       [   0,    4,   58,   82,   22]], dtype=int64)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_gbdt_classification_cm = _gbdt_classification.get_confusion_matrix(y_test, list(_gbdt_classification_predictions))\n",
    "_gbdt_classification_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "2996ad61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2118"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([_gbdt_classification_cm[i][j] for i in range(len(_gbdt_classification_cm)) for j in range(len(_gbdt_classification_cm[i]))  if i==j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "28fda5fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.398     0.317     0.353       123\n",
      "           1      0.529     0.444     0.483       536\n",
      "           2      0.734     0.831     0.780      1863\n",
      "           3      0.496     0.435     0.463       612\n",
      "           4      0.495     0.313     0.384       166\n",
      "\n",
      "    accuracy                          0.650      3300\n",
      "   macro avg      0.530     0.468     0.492      3300\n",
      "weighted avg      0.632     0.650     0.637      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, _knn_classification_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf58497",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "cdf35f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "\n",
      "[[  14   54   36   15    4]\n",
      " [  40  169  224   80   23]\n",
      " [  45  267 1168  321   62]\n",
      " [  18   80  263  212   39]\n",
      " [   4   13   56   67   26]]\n"
     ]
    }
   ],
   "source": [
    "_dt_classification = ClassificationModel(model_name=\"DT\", parameter_dict={})\n",
    "_dt_classification.fit(np.array(X_train[\"Embeds\"].tolist()), y_train)\n",
    "_dt_classification_predictions = _dt_classification.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "print(\"CONFUSION MATRIX\\n\")\n",
    "_dt_classification_cm = _dt_classification.get_confusion_matrix(y_test, list(_dt_classification_predictions))\n",
    "print(_dt_classification_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "09935d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.116     0.114     0.115       123\n",
      "           1      0.290     0.315     0.302       536\n",
      "           2      0.669     0.627     0.647      1863\n",
      "           3      0.305     0.346     0.324       612\n",
      "           4      0.169     0.157     0.163       166\n",
      "\n",
      "    accuracy                          0.482      3300\n",
      "   macro avg      0.310     0.312     0.310      3300\n",
      "weighted avg      0.494     0.482     0.487      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, _dt_classification_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "dcf31ee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1588"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([_dt_classification_cm[i][j] for i in range(len(_dt_classification_cm)) for j in range(len(_dt_classification_cm[i]))  if i==j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "3e759623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  23   45   42   12    1]\n",
      " [  46  163  236   82    9]\n",
      " [  48  235 1260  276   44]\n",
      " [  12   62  290  198   50]\n",
      " [   2   13   47   57   47]]\n",
      "1691\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.176     0.187     0.181       123\n",
      "           1      0.315     0.304     0.309       536\n",
      "           2      0.672     0.676     0.674      1863\n",
      "           3      0.317     0.324     0.320       612\n",
      "           4      0.311     0.283     0.297       166\n",
      "\n",
      "    accuracy                          0.512      3300\n",
      "   macro avg      0.358     0.355     0.356      3300\n",
      "weighted avg      0.511     0.512     0.512      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_dt_classification = ClassificationModel(model_name=\"DT\", parameter_dict={'criterion':'entropy'})\n",
    "_dt_classification.fit(np.array(X_train[\"Embeds\"].tolist()), y_train)\n",
    "_dt_classification_predictions = _dt_classification.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_dt_classification_cm = _dt_classification.get_confusion_matrix(y_test, list(_dt_classification_predictions))\n",
    "print(_dt_classification_cm)\n",
    "print(sum([_dt_classification_cm[i][j] for i in range(len(_dt_classification_cm)) for j in range(len(_dt_classification_cm[i]))  if i==j]))\n",
    "print(metrics.classification_report(y_test, _dt_classification_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "304cb30a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0   44   73    6    0]\n",
      " [   0  130  380   26    0]\n",
      " [   0  159 1617   87    0]\n",
      " [   0   71  490   51    0]\n",
      " [   0   19  112   35    0]]\n",
      "1798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000       123\n",
      "           1      0.307     0.243     0.271       536\n",
      "           2      0.605     0.868     0.713      1863\n",
      "           3      0.249     0.083     0.125       612\n",
      "           4      0.000     0.000     0.000       166\n",
      "\n",
      "    accuracy                          0.545      3300\n",
      "   macro avg      0.232     0.239     0.222      3300\n",
      "weighted avg      0.438     0.545     0.470      3300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91945\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\91945\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\91945\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "_dt_classification = ClassificationModel(model_name=\"DT\", parameter_dict={'max_depth':5})\n",
    "_dt_classification.fit(np.array(X_train[\"Embeds\"].tolist()), y_train)\n",
    "_dt_classification_predictions = _dt_classification.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_dt_classification_cm = _dt_classification.get_confusion_matrix(y_test, list(_dt_classification_predictions))\n",
    "print(_dt_classification_cm)\n",
    "print(sum([_dt_classification_cm[i][j] for i in range(len(_dt_classification_cm)) for j in range(len(_dt_classification_cm[i]))  if i==j]))\n",
    "print(metrics.classification_report(y_test, _dt_classification_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61a90d5",
   "metadata": {},
   "source": [
    "## Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "fb184334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91945\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  34,   67,   21,    0,    1],\n",
       "       [  40,  285,  192,   16,    3],\n",
       "       [   8,  152, 1526,  167,   10],\n",
       "       [   2,   34,  252,  271,   53],\n",
       "       [   0,    0,   15,   93,   58]], dtype=int64)"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_ann_classification = ClassificationModel(model_name=\"ANN\", parameter_dict={})\n",
    "_ann_classification.fit(np.array(X_train[\"Embeds\"].tolist()), y_train)\n",
    "_ann_classification_predictions = _ann_classification.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_ann_classification_cm = _ann_classification.get_confusion_matrix(y_test, list(_ann_classification_predictions))\n",
    "print(\"CONFUSION MATRIX\\n\")\n",
    "_ann_classification_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "6857c798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.405     0.276     0.329       123\n",
      "           1      0.530     0.532     0.531       536\n",
      "           2      0.761     0.819     0.789      1863\n",
      "           3      0.495     0.443     0.468       612\n",
      "           4      0.464     0.349     0.399       166\n",
      "\n",
      "    accuracy                          0.659      3300\n",
      "   macro avg      0.531     0.484     0.503      3300\n",
      "weighted avg      0.646     0.659     0.651      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, _ann_classification_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "a5824397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2174"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([_ann_classification_cm[i][j] for i in range(len(_ann_classification_cm)) for j in range(len(_ann_classification_cm[i]))  if i==j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "0aeed0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  33   68   17    3    2]\n",
      " [  41  221  225   40    9]\n",
      " [  20  140 1535  153   15]\n",
      " [   7   41  244  256   64]\n",
      " [   1    5   13   88   59]]\n",
      "2104\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.324     0.268     0.293       123\n",
      "           1      0.465     0.412     0.437       536\n",
      "           2      0.755     0.824     0.788      1863\n",
      "           3      0.474     0.418     0.444       612\n",
      "           4      0.396     0.355     0.375       166\n",
      "\n",
      "    accuracy                          0.638      3300\n",
      "   macro avg      0.483     0.456     0.467      3300\n",
      "weighted avg      0.622     0.638     0.628      3300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91945\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "_ann_classification = ClassificationModel(model_name=\"ANN\", parameter_dict={'activation':'tanh'})\n",
    "_ann_classification.fit(np.array(X_train[\"Embeds\"].tolist()), y_train)\n",
    "_ann_classification_predictions = _ann_classification.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_ann_classification_cm = _ann_classification.get_confusion_matrix(y_test, list(_ann_classification_predictions))\n",
    "print(_ann_classification_cm)\n",
    "#print(sum([_ann_classification_cm[i][j] for i in range(len(_ann_classification_cm)) for j in range(len(_ann_classification_cm[i]))  if i==j]))\n",
    "print(metrics.classification_report(y_test, _ann_classification_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "0472bace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  23   74   23    2    1]\n",
      " [  25  232  251   22    6]\n",
      " [   6  111 1633  108    5]\n",
      " [   4   34  275  274   25]\n",
      " [   0    5   22   95   44]]\n",
      "2206\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.397     0.187     0.254       123\n",
      "           1      0.509     0.433     0.468       536\n",
      "           2      0.741     0.877     0.803      1863\n",
      "           3      0.547     0.448     0.492       612\n",
      "           4      0.543     0.265     0.356       166\n",
      "\n",
      "    accuracy                          0.668      3300\n",
      "   macro avg      0.547     0.442     0.475      3300\n",
      "weighted avg      0.644     0.668     0.648      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ann_classification = ClassificationModel(model_name=\"ANN\", parameter_dict={'early_stopping':True})\n",
    "_ann_classification.fit(np.array(X_train[\"Embeds\"].tolist()), y_train)\n",
    "_ann_classification_predictions = _ann_classification.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_ann_classification_cm = _ann_classification.get_confusion_matrix(y_test, list(_ann_classification_predictions))\n",
    "print(_ann_classification_cm)\n",
    "print(sum([_ann_classification_cm[i][j] for i in range(len(_ann_classification_cm)) for j in range(len(_ann_classification_cm[i]))  if i==j]))\n",
    "print(metrics.classification_report(y_test, _ann_classification_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "a866ffcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  28   72   19    4    0]\n",
      " [  29  245  233   26    3]\n",
      " [   5  124 1611  119    4]\n",
      " [   4   28  265  288   27]\n",
      " [   1    4   21   85   55]]\n",
      "2227\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.418     0.228     0.295       123\n",
      "           1      0.518     0.457     0.486       536\n",
      "           2      0.750     0.865     0.803      1863\n",
      "           3      0.552     0.471     0.508       612\n",
      "           4      0.618     0.331     0.431       166\n",
      "\n",
      "    accuracy                          0.675      3300\n",
      "   macro avg      0.571     0.470     0.505      3300\n",
      "weighted avg      0.656     0.675     0.659      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ann_classification = ClassificationModel(model_name=\"ANN\", parameter_dict={'early_stopping':True, 'validation_fraction': 0.1})\n",
    "_ann_classification.fit(np.array(X_train[\"Embeds\"].tolist()), y_train)\n",
    "_ann_classification_predictions = _ann_classification.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_ann_classification_cm = _ann_classification.get_confusion_matrix(y_test, list(_ann_classification_predictions))\n",
    "print(_ann_classification_cm)\n",
    "print(sum([_ann_classification_cm[i][j] for i in range(len(_ann_classification_cm)) for j in range(len(_ann_classification_cm[i]))  if i==j]))\n",
    "print(metrics.classification_report(y_test, _ann_classification_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "de799f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  26   73   21    3    0]\n",
      " [  26  223  256   29    2]\n",
      " [   7  111 1633  110    2]\n",
      " [   3   38  265  289   17]\n",
      " [   1    4   27  106   28]]\n",
      "2199\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.413     0.211     0.280       123\n",
      "           1      0.497     0.416     0.453       536\n",
      "           2      0.742     0.877     0.803      1863\n",
      "           3      0.538     0.472     0.503       612\n",
      "           4      0.571     0.169     0.260       166\n",
      "\n",
      "    accuracy                          0.666      3300\n",
      "   macro avg      0.552     0.429     0.460      3300\n",
      "weighted avg      0.643     0.666     0.644      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ann_classification = ClassificationModel(model_name=\"ANN\", parameter_dict={'learning_rate':'invscaling', 'early_stopping':True, 'validation_fraction': 0.1, 'shuffle':True})\n",
    "_ann_classification.fit(np.array(X_train[\"Embeds\"].tolist()), y_train)\n",
    "_ann_classification_predictions = _ann_classification.predict(np.array(X_test[\"Embeds\"].tolist()))\n",
    "_ann_classification_cm = _ann_classification.get_confusion_matrix(y_test, list(_ann_classification_predictions))\n",
    "print(_ann_classification_cm)\n",
    "print(sum([_ann_classification_cm[i][j] for i in range(len(_ann_classification_cm)) for j in range(len(_ann_classification_cm[i]))  if i==j]))\n",
    "print(metrics.classification_report(y_test, _ann_classification_predictions, digits=3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
